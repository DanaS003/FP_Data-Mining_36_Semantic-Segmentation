{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13965826,"sourceType":"datasetVersion","datasetId":8902802},{"sourceId":672965,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":509936,"modelId":524601}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:32:30.696691Z","iopub.execute_input":"2025-12-05T03:32:30.697192Z","iopub.status.idle":"2025-12-05T03:33:38.589315Z","shell.execute_reply.started":"2025-12-05T03:32:30.697168Z","shell.execute_reply":"2025-12-05T03:33:38.588593Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.36.0)\nRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.3.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.5.3)\nRequirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.19)\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.3->segmentation-models-pytorch) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nDownloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, segmentation-models-pytorch\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 segmentation-models-pytorch-0.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom glob import glob\nfrom tqdm import tqdm\nimport time\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:33:41.390214Z","iopub.execute_input":"2025-12-05T03:33:41.391022Z","iopub.status.idle":"2025-12-05T03:33:46.988527Z","shell.execute_reply.started":"2025-12-05T03:33:41.390973Z","shell.execute_reply":"2025-12-05T03:33:46.987749Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Dataset Loader","metadata":{}},{"cell_type":"code","source":"ls /kaggle/input\n\nNUM_CLASSES = 10\nBATCH_SIZE = 16\nEPOCHS = 25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:33:50.401546Z","iopub.execute_input":"2025-12-05T03:33:50.402399Z","iopub.status.idle":"2025-12-05T03:33:50.537553Z","shell.execute_reply.started":"2025-12-05T03:33:50.402377Z","shell.execute_reply":"2025-12-05T03:33:50.536833Z"}},"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mrescuenet-dataset\u001b[0m/  \u001b[01;34msegformer\u001b[0m/\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import glob\ndef get_sorted_paths(folder_path):\n    files = sorted(glob.glob(os.path.join(folder_path, \"*\"))) \n    return files\n\nROOT_INP = \"/kaggle/input/rescuenet-dataset\"\n\ntrain_image_paths = get_sorted_paths(ROOT_INP+'/train/train-org-img')\ntrain_mask_paths = get_sorted_paths(ROOT_INP+'/train/train-label-img')\n\nval_image_paths = get_sorted_paths(ROOT_INP+'/val/val-org-img')\nval_mask_paths = get_sorted_paths(ROOT_INP+'/val/val-label-img')\n\ntest_image_paths = get_sorted_paths(ROOT_INP+'/test/test-org-img')\ntest_mask_paths = get_sorted_paths(ROOT_INP+'/test/test-label-img')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:33:52.045809Z","iopub.execute_input":"2025-12-05T03:33:52.046583Z","iopub.status.idle":"2025-12-05T03:33:52.538315Z","shell.execute_reply.started":"2025-12-05T03:33:52.046555Z","shell.execute_reply":"2025-12-05T03:33:52.537727Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class RescueNetDataset(Dataset):\n    def __init__(self, image_path, mask_path, transform=None, image_size=(512, 512)):\n        self.image_path = image_path\n        self.mask_path = mask_path\n        self.transform = transform\n        self.image_size = image_size\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_path[idx]).convert('RGB')\n        mask = Image.open(self.mask_path[idx]).convert('L')\n\n        if self.transform:\n            image = self.transform(image)\n\n        mask = mask.resize(self.image_size, Image.NEAREST)\n        mask = np.array(mask, dtype=np.int64)\n        # mask = np.clip(mask, 0, 9)\n        mask = torch.from_numpy(mask).long()\n\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:33:53.630693Z","iopub.execute_input":"2025-12-05T03:33:53.631408Z","iopub.status.idle":"2025-12-05T03:33:53.636454Z","shell.execute_reply.started":"2025-12-05T03:33:53.631384Z","shell.execute_reply":"2025-12-05T03:33:53.635841Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Dataset Prep","metadata":{}},{"cell_type":"code","source":"train_test_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n])\n\ntrain_dataset = RescueNetDataset(train_image_paths, train_mask_paths, transform=train_test_transform)\nval_dataset = RescueNetDataset(val_image_paths, val_mask_paths, transform=train_test_transform)\ntest_dataset = RescueNetDataset(test_image_paths, test_mask_paths, transform=train_test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:33:55.337886Z","iopub.execute_input":"2025-12-05T03:33:55.338490Z","iopub.status.idle":"2025-12-05T03:33:55.344223Z","shell.execute_reply.started":"2025-12-05T03:33:55.338464Z","shell.execute_reply":"2025-12-05T03:33:55.343526Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# def get_all_unique_masks(dataloader, max_batches=None):\n#     all_unique = set()\n#     for i, (_, masks) in enumerate(dataloader):\n#         all_unique.update(int(u) for u in torch.unique(masks))\n#         if max_batches is not None and i+1 >= max_batches:\n#             break\n#     return sorted(all_unique)\n\n# # print(\"Train unique (scan 200 batches):\", get_all_unique_masks(train_loader, max_batches=200))\n# # print(\"Val unique   (scan all):       \", get_all_unique_masks(val_loader))\n# print(\"Test unique  (scan all):       \", get_all_unique_masks(test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:06:41.370532Z","iopub.execute_input":"2025-12-04T09:06:41.370721Z","iopub.status.idle":"2025-12-04T09:06:41.387635Z","shell.execute_reply.started":"2025-12-04T09:06:41.370706Z","shell.execute_reply":"2025-12-04T09:06:41.386969Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport segmentation_models_pytorch as smp\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nmodel = smp.Segformer(\n    encoder_name=\"mit_b1\",       \n    encoder_weights=\"imagenet\",  \n    in_channels=3,\n    classes=NUM_CLASSES,                  \n    activation=None              \n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:33:58.999631Z","iopub.execute_input":"2025-12-05T03:33:59.000394Z","iopub.status.idle":"2025-12-05T03:34:07.831622Z","shell.execute_reply.started":"2025-12-05T03:33:59.000368Z","shell.execute_reply":"2025-12-05T03:34:07.830984Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/135 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0175cc36d8084069a72b0e3668cf1e3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/54.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f907cc46ea4d4e2d8d4fff9260618972"}},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Train n Eval","metadata":{}},{"cell_type":"code","source":"print(f\"Train Images: {len(train_image_paths)}, Train Masks: {len(train_mask_paths)}\")\nprint(f\"Val Images: {len(val_image_paths)}, Val Masks: {len(val_mask_paths)}\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"DEVICE USED : {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:13:33.945643Z","iopub.execute_input":"2025-12-04T09:13:33.945954Z","iopub.status.idle":"2025-12-04T09:13:33.950890Z","shell.execute_reply.started":"2025-12-04T09:13:33.945906Z","shell.execute_reply":"2025-12-04T09:13:33.949977Z"}},"outputs":[{"name":"stdout","text":"Train Images: 3595, Train Masks: 3595\nVal Images: 449, Val Masks: 449\nDEVICE USED : cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"class JointLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.ce = nn.CrossEntropyLoss()\n        self.dice = smp.losses.DiceLoss(mode='multiclass', from_logits=True)\n\n    def forward(self, logits, targets):\n        loss_ce = self.ce(logits, targets)\n        loss_dice = self.dice(logits, targets)\n        return loss_ce + loss_dice\n\ntotal_loss_fn = JointLoss()\n\nencoder_params = []\ndecoder_params = []\n\nfor name, param in model.named_parameters():\n    if not param.requires_grad:\n        continue\n    \n    if name.startswith(\"encoder\"):\n        encoder_params.append(param)\n    else:\n        decoder_params.append(param)\n\noptimizer = AdamW(\n    [\n    {'params': encoder_params, 'lr': 6e-4},  \n    {'params': decoder_params, 'lr': 9e-3}   \n], \n    # model.parameters(),\n    weight_decay=1e-2)    \n    # lr=6e-4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:34:07.832638Z","iopub.execute_input":"2025-12-05T03:34:07.832912Z","iopub.status.idle":"2025-12-05T03:34:07.840021Z","shell.execute_reply.started":"2025-12-05T03:34:07.832892Z","shell.execute_reply":"2025-12-05T03:34:07.839325Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from torchmetrics import JaccardIndex\nfrom tqdm.auto import tqdm\n\n# EPOCHS = 1\n\nscheduler = CosineAnnealingLR(\n    optimizer,\n    T_max=EPOCHS,\n    eta_min=1e-6 \n)\n\nmetric_val   = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES, average=None).to(device)\n\nbest_mIoU = 0.0\n\nhistory = {\n    \"train_loss\": [],\n    \"val_loss\": [],\n    \"val_miou\": []\n}\n\nfor epoch in range(EPOCHS):\n\n    model.train()\n    train_loss = 0\n\n    if hasattr(model, 'mod1_detection'): \n        model.mod1_detection.eval()\n        \n    for images, masks in tqdm(train_loader, desc=f\"Train {epoch+1}/{EPOCHS}\"):\n        images, masks = images.to(device), masks.to(device)\n\n        optimizer.zero_grad()\n        preds = model(images)\n        loss = total_loss_fn(preds, masks)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        del preds, loss\n        torch.cuda.empty_cache()\n\n    train_loss /= len(train_loader)\n\n    print(f\"ðŸŽ¯ Train Loss: {train_loss:.4f}\")\n    history[\"train_loss\"].append(train_loss)\n\n    model.eval()\n    val_loss = 0\n    metric_val.reset()\n\n    with torch.no_grad():\n        for images, masks in tqdm(val_loader, desc=f\"Val {epoch+1}/{EPOCHS}\"):\n            images, masks = images.to(device), masks.to(device)\n\n            preds = model(images)\n            loss = total_loss_fn(preds, masks)\n            val_loss += loss.item()\n\n            pred_mask = preds.argmax(dim=1)\n            metric_val.update(pred_mask, masks)\n\n            del preds, loss\n            torch.cuda.empty_cache()\n\n    val_loss /= len(val_loader)\n    iou_val_per_class = metric_val.compute()\n    mIoU_val = iou_val_per_class.mean().item()\n\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_miou\"].append(mIoU_val)\n\n    print(f\"\"\"\n============================== Epoch: {epoch+1}/{EPOCHS}\nTrain Loss: {train_loss:.4f}\nVal Loss:   {val_loss:.4f}   | Val mIoU: {mIoU_val:.4f}\n==============================\n\"\"\")\n\n\n    scheduler.step(val_loss)\n\n    if best_mIoU < mIoU_val:\n        best_mIoU = mIoU_val\n        torch.save(model.state_dict(), \"best_model_segformer_lokal.pth\")\n        print(\"Model disimpan (best so far).\")\n            \nprint(\"Training Selesai!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:13:38.154312Z","iopub.execute_input":"2025-12-04T09:13:38.154893Z","iopub.status.idle":"2025-12-04T10:26:25.550311Z","shell.execute_reply.started":"2025-12-04T09:13:38.154870Z","shell.execute_reply":"2025-12-04T10:26:25.549180Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Train 1/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e62b942c766e4fa59cf3e0978ea365e6"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.5381\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 1/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d51e1337e3b4217938fea9d0a2eab8b"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 1/6\nTrain Loss: 1.5381\nVal Loss:   1.2477   | Val mIoU: 0.2437\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 2/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a02fb8726ea497ba21616cd3aeb0a91"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.1355\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 2/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a984d1220e7e46848957b5bcd23db1ae"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 2/6\nTrain Loss: 1.1355\nVal Loss:   0.9074   | Val mIoU: 0.3503\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 3/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ada68772934ee98100778bafa8a18b"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9956\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 3/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d262a5482f94d7782e31bd6af1b2923"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    self._shutdown_workers()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    if w.is_alive():\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    ^^^^self._shutdown_workers()^\n^^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n    ^^if w.is_alive():\n\n AssertionError: \ncan only test a child process  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0> \n Traceback (most recent call last):\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^self._shutdown_workers()^\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^if w.is_alive():^\n^ ^ ^ ^\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process'^\n ^ ^ ^  ^ ^^ ^^  ^ ^ ^^^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^^ ^ ^ ^ ^^ ^  ^ ^  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^AssertionError^: ^can only test a child process^\n^^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^^\n^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^    ^self._shutdown_workers()^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^if w.is_alive():\n\n AssertionError:    can only test a child process \n  Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    self._shutdown_workers()^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^    if w.is_alive():^\n^ ^ ^  ^\n    File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^^ ^  ^ ^ ^ ^ ^ ^\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n     ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^  ^ ^  ^  ^^  ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\n\nAssertionErrorTraceback (most recent call last):\n:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\ncan only test a child process    self._shutdown_workers()\n\nException ignored in:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>    if w.is_alive():\n\n Traceback (most recent call last):\n    File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n        self._shutdown_workers()^\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^^if w.is_alive():^\n  ^^ ^ ^  ^ ^\n^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    ^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^ ^ ^ ^^ ^ ^ ^ ^ \n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n       assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^ ^ ^  ^ ^ ^ ^  ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: ^can only test a child process^\n^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    self._shutdown_workers()\n\nAssertionError:   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\ncan only test a child process    if w.is_alive():\n\n       ^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    assert self._parent_pid == os.getpid(), 'can only test a child process'\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"\n============================== Epoch: 3/6\nTrain Loss: 0.9956\nVal Loss:   0.8720   | Val mIoU: 0.3587\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 4/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b725dab338e049dd837f9601ba8ca32a"}},"metadata":{}},{"name":"stderr","text":"Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\nException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n\n    self._shutdown_workers()Traceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nself._shutdown_workers()\n    if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n       if w.is_alive():\n    Exception ignored in:   ^ Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^ \n^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0> Traceback (most recent call last):\n\n Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n     ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^self._shutdown_workers()^^\n^    ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^self._shutdown_workers()^    ^^\nif w.is_alive():^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n^    ^ if w.is_alive(): \n^\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  ^    ^   assert self._parent_pid == os.getpid(), 'can only test a child process'^  \n^       ^^^ ^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n ^^^     ^assert self._parent_pid == os.getpid(), 'can only test a child process'^^ \n^ ^  ^^  ^^  ^^^ ^^ ^ ^\n^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n    ^      assert self._parent_pid == os.getpid(), 'can only test a child process'^ assert self._parent_pid == os.getpid(), 'can only test a child process'\n ^^ \n^^ ^^ ^^  ^^ ^^ ^^ ^^  ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^ ^^ ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^^^AssertionError^^: ^^can only test a child process^^^\n^\n^^^AssertionError^Exception ignored in: ^: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>can only test a child process^\n\n^^Exception ignored in: Traceback (most recent call last):\n^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    \n^Traceback (most recent call last):\n^^self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^\n    ^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^self._shutdown_workers()^\n    ^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\nif w.is_alive():^    ^\nif w.is_alive():\n^AssertionError\n^  : \n can only test a child process  AssertionError : \n Exception ignored in:   can only test a child process \n<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>  ^\n ^Traceback (most recent call last):\n^Exception ignored in:  ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>self._shutdown_workers()^\n^\n^^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^^    ^    self._shutdown_workers()^^^\nif w.is_alive():^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n^^\n      ^if w.is_alive():  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^    \n\n assert self._parent_pid == os.getpid(), 'can only test a child process'   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n \n       assert self._parent_pid == os.getpid(), 'can only test a child process'    \n       ^ ^ ^ ^  ^^  ^^^   ^^  ^^^ ^ ^^^ ^^^^ ^^^^^\n ^^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^\n    ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^assert self._parent_pid == os.getpid(), 'can only test a child process'\n^    ^ ^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^   ^^ ^^ ^ ^^  ^^  ^ ^   ^^ ^^^ ^ ^^  ^^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^AssertionError^^: ^^^can only test a child process^^^\n^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^\n^^\nAssertionError^^: Traceback (most recent call last):\n^^can only test a child process  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^\n^^    ^^^Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^^\n\n^^Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^    ^    ^^if w.is_alive():^self._shutdown_workers()^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n^ ^AssertionError     if w.is_alive():: ^\n can only test a child process^ \n  \n AssertionError Exception ignored in:   : <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>  ^ ^\ncan only test a child process Traceback (most recent call last):\n\n^^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^^    ^self._shutdown_workers()Exception ignored in: ^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n    ^^    ^if w.is_alive():^self._shutdown_workers()^\n\n^\n ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^ ^         \n if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n     \n    assert self._parent_pid == os.getpid(), 'can only test a child process'^ \n ^  ^  ^     ^   ^ ^^  ^ ^  ^ ^   ^^^^^ ^^ ^^^^^^\n^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^\n^^^ ^^ ^^\n ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^ ^    ^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^ \n^^  ^^ ^ ^ ^   ^^  ^^^ ^^ ^^^ ^^ ^ ^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^AssertionError^^\n^AssertionError^: ^^can only test a child process: ^^^can only test a child process^^\n^\n^^Exception ignored in: ^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^^\n^\nTraceback (most recent call last):\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^Traceback (most recent call last):\n    ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\nself._shutdown_workers()^^\n^^      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^^\nself._shutdown_workers()    ^if w.is_alive():AssertionError\n^\n :   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n ^^ can only test a child process     \n \nException ignored in: if w.is_alive(): \nAssertionError  <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>: ^\ncan only test a child process ^Traceback (most recent call last):\n\n   File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^Exception ignored in:      <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0> ^\n self._shutdown_workers()Traceback (most recent call last):\n^ ^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    ^^    ^self._shutdown_workers()\n^^^if w.is_alive():  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    \n^if w.is_alive():^^ ^^\n^\n  ^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n ^      \n assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n\n          assert self._parent_pid == os.getpid(), 'can only test a child process'\n  ^ ^^ ^ ^^ ^  ^^^ ^^  ^^ ^^ ^ ^ ^ ^^ \n  ^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  ^     ^^^\nassert self._parent_pid == os.getpid(), 'can only test a child process'^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^\n^    ^^^^ assert self._parent_pid == os.getpid(), 'can only test a child process'^^\n ^^ ^ ^^^   ^ ^ ^ ^^  ^^ ^ ^  ^^ ^ ^^  ^^^^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError\n^^: AssertionError^^: can only test a child process^\n^can only test a child process^^Exception ignored in: ^\n^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>Exception ignored in: ^\n^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^<function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>\n^^    ^Traceback (most recent call last):\nself._shutdown_workers()^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^\n^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^    self._shutdown_workers()^^\n    ^^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^if w.is_alive():    ^^\n^if w.is_alive():^^\n^ \n ^  AssertionError\n :  AssertionError  : can only test a child process  \ncan only test a child process  \n ^Exception ignored in: ^Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0><function _MultiProcessingDataLoaderIter.__del__ at 0x7ea4a91ba3e0>^^\n\n^^Traceback (most recent call last):\n^^Traceback (most recent call last):\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^    self._shutdown_workers()  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1618, in __del__\n^^^\n^    ^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n^self._shutdown_workers()    ^^if w.is_alive():\n^  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\", line 1601, in _shutdown_workers\n\n^^     ^^ if w.is_alive():\n\n \n   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n            assert self._parent_pid == os.getpid(), 'can only test a child process' assert self._parent_pid == os.getpid(), 'can only test a child process'\n ^ ^\n  ^ ^  ^   ^    ^ ^ ^  ^^^ ^ ^^   ^^ \n ^^  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n ^ ^^    ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^\n^^ ^^^\n^^   File \"/usr/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n^^    ^ ^^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^ \n^^   ^ ^  ^^^ ^ ^  ^^ ^ ^^ ^^^^^ ^^ ^^^ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^\nAssertionError^: ^^AssertionError^^^: can only test a child processcan only test a child process^^\n\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^AssertionError^: \ncan only test a child process\nAssertionError: can only test a child process\n","output_type":"stream"},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9116\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 4/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7fd884e8074a489ae876cfcbad12b7"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 4/6\nTrain Loss: 0.9116\nVal Loss:   0.8262   | Val mIoU: 0.3793\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 5/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ddb31a94db4369a759dea04eb29673"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.8631\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 5/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"859105db7fad420a96cd2cba5c6b935e"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 5/6\nTrain Loss: 0.8631\nVal Loss:   0.7731   | Val mIoU: 0.4463\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 6/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2aaadb17f9b488e93f73ec6f3fc94fb"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.8234\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 6/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d78b338f74943f0ab27c0a1b4b20afe"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 6/6\nTrain Loss: 0.8234\nVal Loss:   0.7509   | Val mIoU: 0.4521\n==============================\n\nModel disimpan (best so far).\nTraining Selesai!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# import os\n\n# print(os.getcwd())\n# print(os.listdir())\n# from IPython.display import FileLink\n\n# FileLink(\"best_model_csdnet.pth\")\n# # FileLink(\"history_csdnet.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:13:27.080200Z","iopub.status.idle":"2025-12-04T09:13:27.080464Z","shell.execute_reply.started":"2025-12-04T09:13:27.080352Z","shell.execute_reply":"2025-12-04T09:13:27.080362Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nWORKDIR=\"/kaggle/working\"\noutput_path = WORKDIR+\"/history_segformer_lokal.json\"\n\nwith open(output_path, \"w\") as f:\n    json.dump(history, f, indent=4)\n\nprint(\"File saved to:\", output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T10:27:26.121944Z","iopub.status.idle":"2025-12-04T10:27:26.122219Z","shell.execute_reply.started":"2025-12-04T10:27:26.122091Z","shell.execute_reply":"2025-12-04T10:27:26.122103Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"import torch\nfrom tqdm.auto import tqdm\nfrom torchmetrics import JaccardIndex  \n\ndef test_model(model, test_loader, device):\n    metric = JaccardIndex(\n        task=\"multiclass\", \n        num_classes=NUM_CLASSES, \n        ignore_index=255,\n        average=\"none\" \n    ).to(device)\n\n    model.to(device)\n    \n    model.eval()\n    test_loss = 0.0\n    print(\"Mulai Testing (menggunakan JaccardIndex)...\")\n    \n    with torch.no_grad():\n        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n            \n            images, masks = images.to(device), masks.to(device)\n\n            preds = model(images)\n            \n            loss = total_loss_fn(preds, masks)\n            test_loss += loss.item()\n\n            pred_mask = torch.argmax(preds, dim=1)\n            metric.update(pred_mask, masks)\n    \n    iou_per_class = metric.compute()\n    \n    mIoU = iou_per_class.mean().item()\n    \n    print(\"\\n=== HASIL TESTING ===\")\n    print(f\"Mean IoU (mIoU): {mIoU:.4f}\")\n    print(\"-\" * 30)\n    \n    class_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n                   \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n    \n    for i, iou in enumerate(iou_per_class):\n        name = class_names[i] if i < len(class_names) else f\"Class {i}\"\n        print(f\"{name:25s}: {iou.item():.4f}\")\n        \n    metric.reset()\n    return mIoU, iou_per_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:34:13.683623Z","iopub.execute_input":"2025-12-05T03:34:13.684193Z","iopub.status.idle":"2025-12-05T03:34:17.905587Z","shell.execute_reply.started":"2025-12-05T03:34:13.684168Z","shell.execute_reply":"2025-12-05T03:34:17.904995Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn.functional as F\n\nmodel = smp.Segformer(\n    encoder_name=\"mit_b1\",       \n    encoder_weights=\"imagenet\",  \n    in_channels=3,\n    classes=NUM_CLASSES                  \n    activation=None              \n)\n# /kaggle/input/segformer/pytorch/default/1\n# TMP_DIR = \"/kaggle/input/segformer/pytorch/default/1\"\n\nckpt_path = WORKDIR + \"/best_model_segformer_lokal.pth\"\nckpt = torch.load(ckpt_path, map_location=\"cpu\")\n\nif isinstance(ckpt, dict):\n    if \"model_state_dict\" in ckpt:\n        ckpt_state = ckpt[\"model_state_dict\"]\n    elif \"state_dict\" in ckpt:\n        ckpt_state = ckpt[\"state_dict\"]\n    elif \"model\" in ckpt:\n        ckpt_state = ckpt[\"model\"]\n    else:\n        ckpt_state = ckpt\nelse:\n    ckpt_state = ckpt\n\ntry:\n    model.load_state_dict(ckpt_state)\n    print(\"Checkpoint loaded with strict=True (perfect match).\")\nexcept Exception as e:\n    print(\"Strict load failed:\", e)\n    model_state = model.state_dict()\n    compatible = {}\n    mismatched = []\n    for k, v in ckpt_state.items():\n        if k in model_state:\n            if v.shape == model_state[k].shape:\n                compatible[k] = v\n            else:\n                mismatched.append((k, v.shape, model_state[k].shape))\n    print(f\"Compatible keys: {len(compatible)} / {len(model_state)}\")\n    if mismatched:\n        print(\"Mismatched params (name, ckpt_shape, model_shape) - top 10 shown:\")\n        for item in mismatched[:10]:\n            print(\" \", item)\n    model_state.update(compatible)\n    model.load_state_dict(model_state)\n    print(\"Loaded compatible weights; mismatched layers left as randomly initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:38:07.994432Z","iopub.execute_input":"2025-12-05T03:38:07.995173Z","iopub.status.idle":"2025-12-05T03:38:08.489644Z","shell.execute_reply.started":"2025-12-05T03:38:07.995144Z","shell.execute_reply":"2025-12-05T03:38:08.488950Z"}},"outputs":[{"name":"stdout","text":"Checkpoint loaded with strict=True (perfect match).\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n               \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n\ntest_mIoU, test_iou_per_class = test_model(model, test_loader, device)\n\nprint(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\nprint(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\nprint(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\nprint(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\nprint(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\\n\\n\")\nprint(f\"===================== IoU Per Class ========================\")\nfor i, iou in enumerate(test_iou_per_class):\n        name = class_names[i] if i < len(class_names) else f\"Class {i}\"\n        print(f\"{name:25s}: {iou.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T03:38:11.561559Z","iopub.execute_input":"2025-12-05T03:38:11.562278Z","iopub.status.idle":"2025-12-05T03:38:11.590966Z","shell.execute_reply.started":"2025-12-05T03:38:11.562243Z","shell.execute_reply":"2025-12-05T03:38:11.590049Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/2181163830.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     ]\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_mIoU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iou_per_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_47/326929151.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     ).to(device)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, exclude_state)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                 \u001b[0mthis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"RuntimeError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# import torch\n# import os\n# from matplotlib.patches import Patch\n\n# CLASS_NAMES = [\n#     \"Background\",               \n#     \"Water\",                    \n#     \"Building No Damage\",       \n#     \"Building Minor Damage\",    \n#     \"Building Major Damage\",    \n#     \"Building Total Destruction\",\n#     \"Road-Clear\",               \n#     \"Road-Blocked\",             \n#     \"Vehicle\",                  \n#     \"Tree\",                     \n#     \"Pool\"                      \n# ]\n\n# LABEL_COLORS = np.array([\n#     [0, 0, 0],         # Background \n#     [30, 230, 255],    # Water \n#     [184, 115, 117],   # Building No Damage\n#     [216, 255, 0],     # Building Minor Damage\n#     [252, 199, 0],     # Building Major Damage\n#     [255, 0, 0],       # Building Total Destruction\n#     [140, 140, 140],   # Road-Clear\n#     [151, 0, 255],     # Road-Blocked\n#     [255, 0, 246],     # Vehicle \n#     [0, 255, 0],       # Tree\n#     [244, 255, 0]      # Pool\n# ])\n# def decode_segmap(mask):\n#     r = np.zeros_like(mask).astype(np.uint8)\n#     g = np.zeros_like(mask).astype(np.uint8)\n#     b = np.zeros_like(mask).astype(np.uint8)\n    \n#     for l in range(0, len(LABEL_COLORS)):\n#         idx = mask == l\n#         r[idx] = LABEL_COLORS[l, 0]\n#         g[idx] = LABEL_COLORS[l, 1]\n#         b[idx] = LABEL_COLORS[l, 2]\n        \n#     rgb = np.stack([r, g, b], axis=2)\n#     return rgb\n\n# def find_indices_by_filename(dataset, target_ids):\n#     found_indices = []\n#     for target in target_ids:\n#         found = False\n#         for idx, path in enumerate(dataset.image_path):\n#             if str(target) in os.path.basename(path):\n#                 found_indices.append(idx)\n#                 found = True\n#                 break\n#         if not found:\n#             return \n#     return found_indices\n\n# def visualize_specific_images(model, dataset, target_ids, device, processor):\n#     model.eval()\n    \n#     indices = find_indices_by_filename(dataset, target_ids)\n\n#     num_samples = len(indices)\n#     fig, axes = plt.subplots(num_samples, 3, figsize=(18, 6 * num_samples))\n    \n#     if num_samples == 1:\n#         axes = axes.reshape(1, -1)\n\n#     for row_idx, idx in enumerate(indices):\n#         image, mask = dataset[idx] \n        \n#         filename = os.path.basename(dataset.image_path[idx])\n        \n#         inputs = processor(\n#             images=[image], \n#             return_tensors=\"pt\",\n#             do_resize=False, \n#             do_rescale=False\n#         )\n#         inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n#         with torch.no_grad():\n#             outputs = model(**inputs)\n        \n#         target_sizes = [(mask.shape[0], mask.shape[1])]\n#         pred_map = processor.post_process_semantic_segmentation(\n#             outputs, target_sizes=target_sizes\n#         )[0] \n        \n#         img_np = image.permute(1, 2, 0).numpy()\n        \n#         mask_rgb = decode_segmap(mask.numpy())\n#         pred_rgb = decode_segmap(pred_map.cpu().numpy())\n        \n#         axes[row_idx, 0].imshow(img_np)\n#         axes[row_idx, 0].set_title(f\"ID: {filename}\\nOriginal Image\")\n#         axes[row_idx, 0].axis(\"off\")\n        \n#         axes[row_idx, 1].imshow(mask_rgb)\n#         axes[row_idx, 1].set_title(\"Ground Truth\")\n#         axes[row_idx, 1].axis(\"off\")\n        \n#         axes[row_idx, 2].imshow(pred_rgb)\n#         axes[row_idx, 2].set_title(\"Mask2Former Prediction\")\n#         axes[row_idx, 2].axis(\"off\")\n\n#     handles = [Patch(color=LABEL_COLORS[i]/255.0, label=CLASS_NAMES[i]) for i in range(len(CLASS_NAMES))]\n#     fig.legend(handles=handles, loc='lower center', ncol=6, bbox_to_anchor=(0.5, 0.0), fontsize=12)\n\n#     plt.savefig('visualisasi_prediksi_rescuenet.png', bbox_inches='tight', dpi=300)\n    \n#     plt.tight_layout()\n#     plt.subplots_adjust(bottom=0.08) \n#     plt.show()\n\n# target_ids = [\"10794\", \"10801\", \"10807\"]\n\n# visualize_specific_images(model, test_dataset, target_ids, device, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:13:27.087866Z","iopub.status.idle":"2025-12-04T09:13:27.088183Z","shell.execute_reply.started":"2025-12-04T09:13:27.088073Z","shell.execute_reply":"2025-12-04T09:13:27.088084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.eval()\n# import matplotlib.pyplot as plt\n\n# test_imgs, test_masks = next(iter(test_loader))\n\n# with torch.no_grad():\n#     inputs = [{\"image\": test_imgs[0].to(cfg.MODEL.DEVICE), \"height\": 512, \"width\": 512}]\n    \n#     outputs = model(inputs)\n    \n#     pred_mask = outputs[0][\"sem_seg\"].argmax(dim=0).cpu().numpy()\n\n# plt.figure(figsize=(10, 5))\n# plt.subplot(1, 2, 1); plt.title(\"Prediction\"); plt.imshow(pred_mask)\n# plt.subplot(1, 2, 2); plt.title(\"Ground Truth\"); plt.imshow(test_masks[0])\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T09:13:27.089133Z","iopub.status.idle":"2025-12-04T09:13:27.089364Z","shell.execute_reply.started":"2025-12-04T09:13:27.089248Z","shell.execute_reply":"2025-12-04T09:13:27.089260Z"}},"outputs":[],"execution_count":null}]}