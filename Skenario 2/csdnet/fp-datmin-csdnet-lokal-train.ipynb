{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12690938,"sourceType":"datasetVersion","datasetId":8020112}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:30:12.729611Z","iopub.execute_input":"2025-12-07T01:30:12.729909Z","iopub.status.idle":"2025-12-07T01:31:28.515548Z","shell.execute_reply.started":"2025-12-07T01:30:12.729886Z","shell.execute_reply":"2025-12-07T01:31:28.514736Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->timm) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom glob import glob\nfrom tqdm import tqdm\nimport time\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:28.516975Z","iopub.execute_input":"2025-12-07T01:31:28.517522Z","iopub.status.idle":"2025-12-07T01:31:35.352467Z","shell.execute_reply.started":"2025-12-07T01:31:28.517496Z","shell.execute_reply":"2025-12-07T01:31:35.351840Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Dataset Loader","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input\n\nNUM_CLASSES = 10\nBATCH_SIZE = 4\nEPOCHS = 25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:35.353458Z","iopub.execute_input":"2025-12-07T01:31:35.353832Z","iopub.status.idle":"2025-12-07T01:31:35.489285Z","shell.execute_reply.started":"2025-12-07T01:31:35.353802Z","shell.execute_reply":"2025-12-07T01:31:35.488343Z"}},"outputs":[{"name":"stdout","text":"indo-flood-segmentation-dataset\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import glob\nimport re\ndef sort_files_numerically(directory):\n    files = os.listdir(directory)\n    files_sorted = sorted(files, key=lambda x: int(re.search(r'\\d+', x).group()))\n    return [os.path.join(directory, f) for f in files_sorted]\n\nROOT_INP = \"/kaggle/input/indo-flood-segmentation-dataset\"\n\ntrain_image_paths = sort_files_numerically(ROOT_INP+'/train/train-org-img')\ntrain_mask_paths = sort_files_numerically(ROOT_INP+'/train/train-label-img')\n\nval_image_paths = sort_files_numerically(ROOT_INP+'/val/val-org-img')\nval_mask_paths = sort_files_numerically(ROOT_INP+'/val/val-label-img')\n\ntest_image_paths = sort_files_numerically(ROOT_INP+'/test/test-org-img')\ntest_mask_paths = sort_files_numerically(ROOT_INP+'/test/test-label-img')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:35.491236Z","iopub.execute_input":"2025-12-07T01:31:35.491565Z","iopub.status.idle":"2025-12-07T01:31:35.527967Z","shell.execute_reply.started":"2025-12-07T01:31:35.491541Z","shell.execute_reply":"2025-12-07T01:31:35.527417Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class FloodDataset(Dataset):\n    def __init__(self, image_path, mask_path, transform=None, image_size=(512, 512)):\n        self.image_path = image_path\n        self.mask_path = mask_path\n        self.transform = transform\n        self.image_size = image_size\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_path[idx]).convert('RGB')\n        mask = Image.open(self.mask_path[idx]).convert('L')\n\n        if self.transform:\n            image = self.transform(image)\n\n        mask = mask.resize(self.image_size, Image.NEAREST)\n        mask = np.array(mask, dtype=np.int64)\n        mask = np.clip(mask, 0, 9)\n        mask = torch.from_numpy(mask).long()\n\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:35.528756Z","iopub.execute_input":"2025-12-07T01:31:35.529015Z","iopub.status.idle":"2025-12-07T01:31:35.534831Z","shell.execute_reply.started":"2025-12-07T01:31:35.528993Z","shell.execute_reply":"2025-12-07T01:31:35.534190Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Dataset Prep","metadata":{}},{"cell_type":"code","source":"train_test_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = FloodDataset(train_image_paths, train_mask_paths, transform=train_test_transform)\nval_dataset = FloodDataset(val_image_paths, val_mask_paths, transform=train_test_transform)\ntest_dataset = FloodDataset(test_image_paths, test_mask_paths, transform=train_test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:35.535577Z","iopub.execute_input":"2025-12-07T01:31:35.535903Z","iopub.status.idle":"2025-12-07T01:31:35.555056Z","shell.execute_reply.started":"2025-12-07T01:31:35.535880Z","shell.execute_reply":"2025-12-07T01:31:35.554435Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# def get_all_unique_masks(dataloader, max_batches=None):\n#     all_unique = set()\n#     for i, (_, masks) in enumerate(dataloader):\n#         all_unique.update(int(u) for u in torch.unique(masks))\n#         if max_batches is not None and i+1 >= max_batches:\n#             break\n#     return sorted(all_unique)\n\n# # print(\"Train unique (scan 200 batches):\", get_all_unique_masks(train_loader, max_batches=200))\n# # print(\"Val unique   (scan all):       \", get_all_unique_masks(val_loader))\n# print(\"Test unique  (scan all):       \", get_all_unique_masks(test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:35.555780Z","iopub.execute_input":"2025-12-07T01:31:35.556036Z","iopub.status.idle":"2025-12-07T01:31:35.570568Z","shell.execute_reply.started":"2025-12-07T01:31:35.556010Z","shell.execute_reply":"2025-12-07T01:31:35.569731Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"import timm\n\nclass DWSC(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n        super().__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, \n                                   padding, groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.bn(x)\n        return self.relu(x)\n\nclass ASPP(nn.Module):\n    def __init__(self, in_channels, out_channels=256):\n        super().__init__()\n        dilations = [1, 6, 12, 18]\n        self.aspp_blocks = nn.ModuleList()\n        \n        self.aspp_blocks.append(nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        ))\n\n        for dilation in dilations[1:]:\n            self.aspp_blocks.append(nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n                nn.BatchNorm2d(out_channels),\n                nn.ReLU(inplace=True)\n            ))\n\n        self.global_pool = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.project = nn.Sequential(\n            nn.Conv2d(out_channels * 5, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5)\n        )\n\n    def forward(self, x):\n        res = []\n        for block in self.aspp_blocks:\n            res.append(block(x))\n        \n        g = self.global_pool(x)\n        g = F.interpolate(g, size=x.shape[2:], mode='bilinear', align_corners=False)\n        res.append(g)\n        \n        res = torch.cat(res, dim=1)\n        return self.project(res)\n\nclass TargetedEnhancementModule(nn.Module):\n    def __init__(self, f1_channels, detector_channels=256, fusion_dim=256):\n        super().__init__()\n        self.aspp_f1 = ASPP(f1_channels, fusion_dim)\n        \n        self.phi = nn.Sequential(\n            nn.Conv2d(detector_channels, fusion_dim, 1),\n            nn.BatchNorm2d(fusion_dim),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, f1, f_det):\n        \n        f1_processed = self.aspp_f1(f1)\n        \n        f_det_processed = self.phi(f_det)\n        f_det_resized = F.interpolate(f_det_processed, size=f1_processed.shape[2:], \n                                      mode='bilinear', align_corners=False)\n        \n        return f1_processed * f_det_resized\n\nclass DeepContextualAttention(nn.Module):\n    def __init__(self, in_channels, dim=256):\n        super().__init__()\n        self.dwsc_in = DWSC(in_channels, dim)\n        \n        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=4, dim_feedforward=dim*2, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n        \n        self.aspp = ASPP(dim, dim)\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        \n        x = self.dwsc_in(x) # (B, dim, H, W)\n        \n        tokens = x.flatten(2).transpose(1, 2)\n        \n        tokens = self.transformer(tokens)\n        \n        x_trans = tokens.transpose(1, 2).view(B, -1, H, W)\n        \n        x_out = self.aspp(x_trans)\n        \n        return x_out\n\nclass MultiScaleFusion(nn.Module):\n    def __init__(self, f2_channels, f3_channels, out_dim=256):\n        super().__init__()\n        self.psi2 = nn.Conv2d(f2_channels, out_dim, 1)\n        self.psi3 = nn.Conv2d(f3_channels, out_dim, 1)\n        \n        self.fusion_conv = nn.Sequential(\n            nn.Conv2d(out_dim * 2, out_dim, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_dim),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, f2, f3):\n        f2_hat = self.psi2(f2)\n        f3_hat = self.psi3(f3)\n        \n        f3_hat_up = F.interpolate(f3_hat, size=f2_hat.shape[2:], mode='bilinear', align_corners=False)\n        \n        f_gen = torch.cat([f2_hat, f3_hat_up], dim=1)\n        return self.fusion_conv(f_gen)\n\nclass CSDNet(nn.Module):\n    def __init__(self, num_classes=NUM_CLASSES):\n        super().__init__()\n        \n        self.encoder = timm.create_model(\n            \"efficientnet_b5\",\n            pretrained=True,\n            features_only=True,\n            out_indices=(0, 1, 2, 3) \n        )\n        \n        dims = self.encoder.feature_info.channels() \n        f1_c, f2_c, f3_c, f4_c = dims[0], dims[1], dims[2], dims[3]\n        \n        fusion_dim = 128 \n        \n        self.mod1_detection = TargetedEnhancementModule(f1_c, detector_channels=256, fusion_dim=fusion_dim)\n        \n        self.mod2_transformer = DeepContextualAttention(f4_c, dim=fusion_dim)\n        \n        self.mod3_cnn = MultiScaleFusion(f2_c, f3_c, out_dim=fusion_dim)\n        \n        self.classifier = nn.Sequential(\n            nn.Conv2d(fusion_dim * 3, 256, 3, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Conv2d(256, num_classes, 1)\n        )\n        \n        self.detector_dummy_layer = nn.Conv2d(3, 256, kernel_size=32, stride=32) \n\n    def get_detection_features(self, x):\n        with torch.no_grad(): \n            det_feats = self.detector_dummy_layer(x) \n        return det_feats\n\n    def forward(self, x):\n        input_shape = x.shape[2:]\n        \n        feats = self.encoder(x)\n        f1, f2, f3, f4 = feats[0], feats[1], feats[2], feats[3]\n        \n        f_det_raw = self.get_detection_features(x)\n        \n        feat_branch1 = self.mod1_detection(f1, f_det_raw) \n        \n        feat_branch2 = self.mod2_transformer(f4)\n        \n        feat_branch3 = self.mod3_cnn(f2, f3)\n        \n        target_size = feat_branch1.shape[2:]\n        \n        feat_branch2_up = F.interpolate(feat_branch2, size=target_size, mode='bilinear', align_corners=False)\n        feat_branch3_up = F.interpolate(feat_branch3, size=target_size, mode='bilinear', align_corners=False)\n        \n        f_final = torch.cat([feat_branch1, feat_branch2_up, feat_branch3_up], dim=1)\n        \n        logits = self.classifier(f_final)\n        \n        logits = F.interpolate(logits, size=input_shape, mode='bilinear', align_corners=False)\n        \n        return logits\n\n# model = CSDNet(num_classes=NUM_CLASSES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:35.571413Z","iopub.execute_input":"2025-12-07T01:31:35.571716Z","iopub.status.idle":"2025-12-07T01:31:39.207042Z","shell.execute_reply.started":"2025-12-07T01:31:35.571686Z","shell.execute_reply":"2025-12-07T01:31:39.206440Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Train n Eval","metadata":{}},{"cell_type":"code","source":"print(f\"Train Images: {len(train_image_paths)}, Train Masks: {len(train_mask_paths)}\")\nprint(f\"Val Images: {len(val_image_paths)}, Val Masks: {len(val_mask_paths)}\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"DEVICE USED : {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:39.207820Z","iopub.execute_input":"2025-12-07T01:31:39.208035Z","iopub.status.idle":"2025-12-07T01:31:39.266307Z","shell.execute_reply.started":"2025-12-07T01:31:39.208018Z","shell.execute_reply":"2025-12-07T01:31:39.265528Z"}},"outputs":[{"name":"stdout","text":"Train Images: 116, Train Masks: 116\nVal Images: 14, Val Masks: 14\nDEVICE USED : cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model = CSDNet(num_classes=NUM_CLASSES).to(device)\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0, alpha=None, ignore_index=255):\n        super().__init__()\n        self.gamma = gamma\n        self.ce = nn.CrossEntropyLoss(reduction='none', weight=alpha, ignore_index=ignore_index)\n\n    def forward(self, logits, targets):\n        ce_loss = self.ce(logits, targets) \n        pt = torch.exp(-ce_loss)\n        focal_loss = (1 - pt) ** self.gamma * ce_loss\n        return focal_loss.mean() \n\n\nclass JaccardLoss(nn.Module):\n    def __init__(self, eps=1e-7):\n        super().__init__()\n        self.eps = eps\n\n    def forward(self, logits, targets):\n        num_classes = logits.shape[1]\n        preds = torch.softmax(logits, dim=1)\n\n        target_1hot = torch.nn.functional.one_hot(targets, num_classes).permute(0,3,1,2)\n\n        intersection = (preds * target_1hot).sum(dim=(2,3))\n        union = preds.sum(dim=(2,3)) + target_1hot.sum(dim=(2,3)) - intersection\n\n        iou = (intersection + self.eps) / (union + self.eps)\n        return 1 - iou.mean()\n\n\nfocal_loss = FocalLoss(gamma=2.0)\njaccard_loss = JaccardLoss()\n\n\ndef total_loss_fn(pred, target):\n    return focal_loss(pred, target) + jaccard_loss(pred, target)\n\noptimizer = torch.optim.SGD(\n    model.parameters(),\n    lr=0.01,\n    momentum=0.9,\n    weight_decay=1e-4\n)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode='min',\n    patience=10,\n    factor=0.1,\n    min_lr=1e-4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:39.269348Z","iopub.execute_input":"2025-12-07T01:31:39.269670Z","iopub.status.idle":"2025-12-07T01:31:42.457057Z","shell.execute_reply.started":"2025-12-07T01:31:39.269650Z","shell.execute_reply":"2025-12-07T01:31:42.456443Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7f5c904b5c342528f53a1db6447adb5"}},"metadata":{}},{"name":"stderr","text":"Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from torchmetrics import JaccardIndex\nfrom tqdm.auto import tqdm\n\nmetric_val   = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES, average=None).to(device)\n\nbest_mIoU = 0.0\n\nhistory = {\n    \"train_loss\": [],\n    \"val_loss\": [],\n    \"val_miou\": []\n}\n\nfor epoch in range(EPOCHS):\n\n    model.train()\n    train_loss = 0\n    \n    if hasattr(model, 'detector_dummy_layer'):\n        model.detector_dummy_layer.eval()\n\n    for images, masks in tqdm(train_loader, desc=f\"Train {epoch+1}/{EPOCHS}\"):\n        images, masks = images.to(device), masks.to(device)\n\n        optimizer.zero_grad()\n        preds = model(images)\n        loss = total_loss_fn(preds, masks)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    train_loss /= len(train_loader)\n\n    print(f\"ðŸŽ¯ Train Loss: {train_loss:.4f}\")\n    history[\"train_loss\"].append(train_loss)\n\n    model.eval()\n    val_loss = 0\n    metric_val.reset()\n\n    with torch.no_grad():\n        for images, masks in tqdm(val_loader, desc=f\"Val {epoch+1}/{EPOCHS}\"):\n            images, masks = images.to(device), masks.to(device)\n\n            preds = model(images)\n            loss = total_loss_fn(preds, masks)\n            val_loss += loss.item()\n\n            pred_mask = preds.argmax(dim=1)\n            metric_val.update(pred_mask, masks)\n\n    val_loss /= len(val_loader)\n    iou_val_per_class = metric_val.compute()\n    mIoU_val = iou_val_per_class.mean().item()\n\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_miou\"].append(mIoU_val)\n\n    print(f\"\"\"\n============================== Epoch: {epoch+1}/{EPOCHS}\nTrain Loss: {train_loss:.4f}\nVal Loss:   {val_loss:.4f}   | Val mIoU: {mIoU_val:.4f}\n==============================\n\"\"\")\n\n\n    scheduler.step(val_loss)\n\n    if best_mIoU < mIoU_val:\n        best_mIoU = mIoU_val\n        torch.save(model.state_dict(), \"best_model_csdnet_lokal.pth\")\n        print(\"Model disimpan (best so far).\")\n            \nprint(\"Training Selesai!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:31:42.457801Z","iopub.execute_input":"2025-12-07T01:31:42.458023Z","iopub.status.idle":"2025-12-07T01:46:44.056663Z","shell.execute_reply.started":"2025-12-07T01:31:42.457999Z","shell.execute_reply":"2025-12-07T01:46:44.055698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Train 1/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44f5093334e64fc29efc752d91694fa4"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 2.1320\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 1/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81893ed91566484fba13d1558022de86"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 1/25\nTrain Loss: 2.1320\nVal Loss:   3.1306   | Val mIoU: 0.0495\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 2/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945ce1dcd3cd42a79028026ed7a2c3c0"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.8645\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 2/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a059f5517034106bb30382abe03db4a"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 2/25\nTrain Loss: 1.8645\nVal Loss:   2.0242   | Val mIoU: 0.0997\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 3/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f4fadf89ab4adcaa91f7ec3ef980da"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.7180\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 3/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5ab9103137e4423925c9cccd02c609f"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 3/25\nTrain Loss: 1.7180\nVal Loss:   1.6818   | Val mIoU: 0.1717\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 4/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78521b8859324fa5937a9502d418a520"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.6406\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 4/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"824e9750fc5f4b11b542a3e0b7e0968e"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 4/25\nTrain Loss: 1.6406\nVal Loss:   1.5174   | Val mIoU: 0.2354\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 5/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f48396e3484a413085239a4f2a62a39e"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.6024\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 5/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96524e34c6af46308d1cff6ff2a10304"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 5/25\nTrain Loss: 1.6024\nVal Loss:   1.6156   | Val mIoU: 0.2055\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 6/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac8c0fe7eafd4230814b541607bd470f"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.5892\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 6/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"990af461e3ca4fce9f087f49926e002c"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 6/25\nTrain Loss: 1.5892\nVal Loss:   1.4430   | Val mIoU: 0.2410\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 7/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c129a81fa704496b8ce25315dbd393d"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.4976\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 7/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f29bf70ec1644c19af5f4060b7339a4f"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 7/25\nTrain Loss: 1.4976\nVal Loss:   1.5709   | Val mIoU: 0.2240\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 8/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c81fe97a7abf4a3581abee50f6e9504b"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.4656\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 8/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d552dbf56fc4204ae1d9a3a2d0d0f7d"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 8/25\nTrain Loss: 1.4656\nVal Loss:   1.4921   | Val mIoU: 0.2406\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 9/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"882b2175cb5946a4a8f7ad3211923193"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.4090\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 9/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dd86c3c290b4c8082a3fcebd3eed82f"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 9/25\nTrain Loss: 1.4090\nVal Loss:   1.6271   | Val mIoU: 0.2382\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 10/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ea1a27627b4e81a64f21c65f2306b5"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.3796\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 10/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14cf98814ec6481391be7054df4df3dc"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 10/25\nTrain Loss: 1.3796\nVal Loss:   1.4513   | Val mIoU: 0.2571\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 11/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dfb4acc330c48aa8c901f0e9b00d00b"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.3192\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 11/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aebb23caa74f46b9ade422a1e5d454f8"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 11/25\nTrain Loss: 1.3192\nVal Loss:   1.4345   | Val mIoU: 0.2729\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 12/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cc101bf1b3242eea182cf975fae990c"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2778\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 12/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f0938220e643f28e86307d4fb113f6"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 12/25\nTrain Loss: 1.2778\nVal Loss:   1.3388   | Val mIoU: 0.2983\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 13/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"319cacd3cbcf4a47bfca3ea3580c77a2"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2790\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 13/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22e056ec79014e37adf5b6b28fb9845e"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 13/25\nTrain Loss: 1.2790\nVal Loss:   1.4283   | Val mIoU: 0.2698\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 14/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87367f9f0b184ee998abca1500a9913d"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2836\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 14/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a90fbf63c2374a48afac5da8fad7762d"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 14/25\nTrain Loss: 1.2836\nVal Loss:   1.5384   | Val mIoU: 0.2114\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 15/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6326a4fa35047338530c62fd65022e2"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2767\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 15/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ee9f8c47dc54ef9a8293bd8a932bdfd"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 15/25\nTrain Loss: 1.2767\nVal Loss:   1.6644   | Val mIoU: 0.2583\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 16/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7af7d95061a4ecbb7720ce7ecbc607a"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2312\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 16/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4de5ba4f02964cf1b8022fe1f713e526"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 16/25\nTrain Loss: 1.2312\nVal Loss:   1.4558   | Val mIoU: 0.2690\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 17/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59986c2660144b8795be7362be5dce84"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2140\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 17/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eaaace7174db484393934caa0e109326"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 17/25\nTrain Loss: 1.2140\nVal Loss:   1.3434   | Val mIoU: 0.2945\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 18/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"107a5e84d633406f9f57fcc38226a2de"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.1021\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 18/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28d29bcdd6d14d65858db834f3963bf4"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 18/25\nTrain Loss: 1.1021\nVal Loss:   1.6919   | Val mIoU: 0.2870\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 19/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"845e515096f542c7b53e2c39b3cc9465"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.1091\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 19/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffd8695c0a7640e79f664ad0e3e8721a"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 19/25\nTrain Loss: 1.1091\nVal Loss:   1.4378   | Val mIoU: 0.3202\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 20/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"636851e19ad44469b6d57e379031b1df"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.0377\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 20/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3e6ebe6197a470191895130c2c4cf56"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 20/25\nTrain Loss: 1.0377\nVal Loss:   1.4706   | Val mIoU: 0.3081\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 21/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"490c96900c664922b2fc4e29d0756973"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.0210\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 21/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f37ec775ba2458e99d19a5308d1d810"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 21/25\nTrain Loss: 1.0210\nVal Loss:   1.4426   | Val mIoU: 0.3066\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 22/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3b34c56fde4cb9a84c983760c511a6"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9918\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 22/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d99309ce87934a90b5d6ef769ebd3c14"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 22/25\nTrain Loss: 0.9918\nVal Loss:   1.4703   | Val mIoU: 0.3168\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 23/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac1d105f12c44662a69fe8cd138aab8f"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9770\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 23/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3d88c1f07bb4243a4b6176aa58de61e"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 23/25\nTrain Loss: 0.9770\nVal Loss:   1.5341   | Val mIoU: 0.3069\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 24/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"168f8c514be54927a82cad9656e34b0e"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9506\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 24/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05f44e385b954064a64f87c756d8c879"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 24/25\nTrain Loss: 0.9506\nVal Loss:   1.4270   | Val mIoU: 0.3421\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 25/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31b6ab6d31694f0a8f5966a4f288e12b"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9496\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 25/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dc9ac029d0e44a292f12224f781ea91"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 25/25\nTrain Loss: 0.9496\nVal Loss:   1.4380   | Val mIoU: 0.3430\n==============================\n\nModel disimpan (best so far).\nTraining Selesai!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import json\n\nWORKDIR=\"/kaggle/working\"\noutput_path = WORKDIR+\"/history_csdnet_lokal.json\"\n\nwith open(output_path, \"w\") as f:\n    json.dump(history, f, indent=4)\n\nprint(\"File saved to:\", output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:48:05.571909Z","iopub.execute_input":"2025-12-07T01:48:05.572455Z","iopub.status.idle":"2025-12-07T01:48:05.578052Z","shell.execute_reply.started":"2025-12-07T01:48:05.572428Z","shell.execute_reply":"2025-12-07T01:48:05.577278Z"}},"outputs":[{"name":"stdout","text":"File saved to: /kaggle/working/history_csdnet_lokal.json\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"import torch\nfrom tqdm.auto import tqdm\nfrom torchmetrics import JaccardIndex  \n\ndef test_model(model, test_loader, device):\n    metric = JaccardIndex(\n        task=\"multiclass\", \n        num_classes=NUM_CLASSES, \n        ignore_index=255,\n        average=\"none\" \n    ).to(device)\n\n    model.to(device)\n    \n    model.eval()\n    test_loss = 0.0\n    print(\"Mulai Testing (menggunakan JaccardIndex)...\")\n    \n    with torch.no_grad():\n        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n            \n            images, masks = images.to(device), masks.to(device)\n\n            preds = model(images)\n            \n            loss = total_loss_fn(preds, masks)\n            test_loss += loss.item()\n\n            pred_mask = torch.argmax(preds, dim=1)\n            metric.update(pred_mask, masks)\n    \n    iou_per_class = metric.compute()\n    \n    mIoU = iou_per_class.mean().item()\n    \n    print(\"\\n=== HASIL TESTING ===\")\n    print(f\"Mean IoU (mIoU): {mIoU:.4f}\")\n    print(\"-\" * 30)\n    \n    class_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n                   \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n    \n    for i, iou in enumerate(iou_per_class):\n        name = class_names[i] if i < len(class_names) else f\"Class {i}\"\n        print(f\"{name:25s}: {iou.item():.4f}\")\n        \n    metric.reset()\n    return mIoU, iou_per_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:46:44.064164Z","iopub.execute_input":"2025-12-07T01:46:44.064331Z","iopub.status.idle":"2025-12-07T01:46:44.085494Z","shell.execute_reply.started":"2025-12-07T01:46:44.064318Z","shell.execute_reply":"2025-12-07T01:46:44.084816Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn.functional as F\n\nmodel = CSDNet(num_classes=NUM_CLASSES).to(device)\n\nckpt_path = WORKDIR + \"/best_model_csdnet_lokal.pth\"\nckpt = torch.load(ckpt_path, map_location=\"cpu\")\n\nif isinstance(ckpt, dict):\n    if \"model_state_dict\" in ckpt:\n        ckpt_state = ckpt[\"model_state_dict\"]\n    elif \"state_dict\" in ckpt:\n        ckpt_state = ckpt[\"state_dict\"]\n    elif \"model\" in ckpt:\n        ckpt_state = ckpt[\"model\"]\n    else:\n        ckpt_state = ckpt\nelse:\n    ckpt_state = ckpt\n\ntry:\n    model.load_state_dict(ckpt_state)\n    print(\"Checkpoint loaded with strict=True (perfect match).\")\nexcept Exception as e:\n    print(\"Strict load failed:\", e)\n    model_state = model.state_dict()\n    compatible = {}\n    mismatched = []\n    for k, v in ckpt_state.items():\n        if k in model_state:\n            if v.shape == model_state[k].shape:\n                compatible[k] = v\n            else:\n                mismatched.append((k, v.shape, model_state[k].shape))\n    print(f\"Compatible keys: {len(compatible)} / {len(model_state)}\")\n    if mismatched:\n        print(\"Mismatched params (name, ckpt_shape, model_shape) - top 10 shown:\")\n        for item in mismatched[:10]:\n            print(\" \", item)\n    model_state.update(compatible)\n    model.load_state_dict(model_state)\n    print(\"Loaded compatible weights; mismatched layers left as randomly initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:46:44.086299Z","iopub.execute_input":"2025-12-07T01:46:44.087125Z","iopub.status.idle":"2025-12-07T01:46:45.027763Z","shell.execute_reply.started":"2025-12-07T01:46:44.087107Z","shell.execute_reply":"2025-12-07T01:46:45.026967Z"}},"outputs":[{"name":"stderr","text":"Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n","output_type":"stream"},{"name":"stdout","text":"Checkpoint loaded with strict=True (perfect match).\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n                   \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n\ntest_mIoU, test_iou_per_class = test_model(model, test_loader, device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:48:54.534308Z","iopub.execute_input":"2025-12-07T01:48:54.534680Z","iopub.status.idle":"2025-12-07T01:48:56.252840Z","shell.execute_reply.started":"2025-12-07T01:48:54.534656Z","shell.execute_reply":"2025-12-07T01:48:56.252246Z"}},"outputs":[{"name":"stdout","text":"Mulai Testing (menggunakan JaccardIndex)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ae9389ed0e045918b6bdc1ba68a9cf1"}},"metadata":{}},{"name":"stdout","text":"\n=== HASIL TESTING ===\nMean IoU (mIoU): 0.3852\n------------------------------\nBackground               : 0.2548\nBuilding Flooded         : 0.7821\nBuilding Non-Flooded     : 0.6826\nRoad Flooded             : 0.3110\nRoad Non-Flooded         : 0.2682\nWater                    : 0.2146\nTree                     : 0.5634\nVehicle                  : 0.0910\nPool                     : 0.0000\nGrass                    : 0.6843\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# import torch\n# import os\n# from matplotlib.patches import Patch\n\n# CLASS_NAMES = [\n#     \"Background\",               \n#     \"Water\",                    \n#     \"Building No Damage\",       \n#     \"Building Minor Damage\",    \n#     \"Building Major Damage\",    \n#     \"Building Total Destruction\",\n#     \"Road-Clear\",               \n#     \"Road-Blocked\",             \n#     \"Vehicle\",                  \n#     \"Tree\",                     \n#     \"Pool\"                      \n# ]\n\n# LABEL_COLORS = np.array([\n#     [0, 0, 0],         # Background \n#     [30, 230, 255],    # Water \n#     [184, 115, 117],   # Building No Damage\n#     [216, 255, 0],     # Building Minor Damage\n#     [252, 199, 0],     # Building Major Damage\n#     [255, 0, 0],       # Building Total Destruction\n#     [140, 140, 140],   # Road-Clear\n#     [151, 0, 255],     # Road-Blocked\n#     [255, 0, 246],     # Vehicle \n#     [0, 255, 0],       # Tree\n#     [244, 255, 0]      # Pool\n# ])\n# def decode_segmap(mask):\n#     r = np.zeros_like(mask).astype(np.uint8)\n#     g = np.zeros_like(mask).astype(np.uint8)\n#     b = np.zeros_like(mask).astype(np.uint8)\n    \n#     for l in range(0, len(LABEL_COLORS)):\n#         idx = mask == l\n#         r[idx] = LABEL_COLORS[l, 0]\n#         g[idx] = LABEL_COLORS[l, 1]\n#         b[idx] = LABEL_COLORS[l, 2]\n        \n#     rgb = np.stack([r, g, b], axis=2)\n#     return rgb\n\n# def find_indices_by_filename(dataset, target_ids):\n#     found_indices = []\n#     for target in target_ids:\n#         found = False\n#         for idx, path in enumerate(dataset.image_path):\n#             if str(target) in os.path.basename(path):\n#                 found_indices.append(idx)\n#                 found = True\n#                 break\n#         if not found:\n#             return \n#     return found_indices\n\n# def visualize_specific_images(model, dataset, target_ids, device, processor):\n#     model.eval()\n    \n#     indices = find_indices_by_filename(dataset, target_ids)\n\n#     num_samples = len(indices)\n#     fig, axes = plt.subplots(num_samples, 3, figsize=(18, 6 * num_samples))\n    \n#     if num_samples == 1:\n#         axes = axes.reshape(1, -1)\n\n#     for row_idx, idx in enumerate(indices):\n#         image, mask = dataset[idx] \n        \n#         filename = os.path.basename(dataset.image_path[idx])\n        \n#         inputs = processor(\n#             images=[image], \n#             return_tensors=\"pt\",\n#             do_resize=False, \n#             do_rescale=False\n#         )\n#         inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n#         with torch.no_grad():\n#             outputs = model(**inputs)\n        \n#         target_sizes = [(mask.shape[0], mask.shape[1])]\n#         pred_map = processor.post_process_semantic_segmentation(\n#             outputs, target_sizes=target_sizes\n#         )[0] \n        \n#         img_np = image.permute(1, 2, 0).numpy()\n        \n#         mask_rgb = decode_segmap(mask.numpy())\n#         pred_rgb = decode_segmap(pred_map.cpu().numpy())\n        \n#         axes[row_idx, 0].imshow(img_np)\n#         axes[row_idx, 0].set_title(f\"ID: {filename}\\nOriginal Image\")\n#         axes[row_idx, 0].axis(\"off\")\n        \n#         axes[row_idx, 1].imshow(mask_rgb)\n#         axes[row_idx, 1].set_title(\"Ground Truth\")\n#         axes[row_idx, 1].axis(\"off\")\n        \n#         axes[row_idx, 2].imshow(pred_rgb)\n#         axes[row_idx, 2].set_title(\"Mask2Former Prediction\")\n#         axes[row_idx, 2].axis(\"off\")\n\n#     handles = [Patch(color=LABEL_COLORS[i]/255.0, label=CLASS_NAMES[i]) for i in range(len(CLASS_NAMES))]\n#     fig.legend(handles=handles, loc='lower center', ncol=6, bbox_to_anchor=(0.5, 0.0), fontsize=12)\n\n#     plt.savefig('visualisasi_prediksi_rescuenet.png', bbox_inches='tight', dpi=300)\n    \n#     plt.tight_layout()\n#     plt.subplots_adjust(bottom=0.08) \n#     plt.show()\n\n# target_ids = [\"10794\", \"10801\", \"10807\"]\n\n# visualize_specific_images(model, test_dataset, target_ids, device, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:46:47.063756Z","iopub.execute_input":"2025-12-07T01:46:47.064368Z","iopub.status.idle":"2025-12-07T01:46:47.069141Z","shell.execute_reply.started":"2025-12-07T01:46:47.064348Z","shell.execute_reply":"2025-12-07T01:46:47.068438Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# model.eval()\n# import matplotlib.pyplot as plt\n\n# test_imgs, test_masks = next(iter(test_loader))\n\n# with torch.no_grad():\n#     inputs = [{\"image\": test_imgs[0].to(cfg.MODEL.DEVICE), \"height\": 512, \"width\": 512}]\n    \n#     outputs = model(inputs)\n    \n#     pred_mask = outputs[0][\"sem_seg\"].argmax(dim=0).cpu().numpy()\n\n# plt.figure(figsize=(10, 5))\n# plt.subplot(1, 2, 1); plt.title(\"Prediction\"); plt.imshow(pred_mask)\n# plt.subplot(1, 2, 2); plt.title(\"Ground Truth\"); plt.imshow(test_masks[0])\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T01:46:47.069938Z","iopub.execute_input":"2025-12-07T01:46:47.070747Z","iopub.status.idle":"2025-12-07T01:46:47.088488Z","shell.execute_reply.started":"2025-12-07T01:46:47.070729Z","shell.execute_reply":"2025-12-07T01:46:47.087843Z"}},"outputs":[],"execution_count":17}]}