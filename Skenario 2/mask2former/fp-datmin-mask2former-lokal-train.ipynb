{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13965826,"sourceType":"datasetVersion","datasetId":8902802}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip uninstall -y transformers accelerate tokenizers numpy\n\n!pip install numpy==1.26.4\n!pip install -U transformers accelerate tokenizers evaluate torchmetrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:13:16.978253Z","iopub.execute_input":"2025-12-05T04:13:16.978536Z","iopub.status.idle":"2025-12-05T04:15:01.862227Z","shell.execute_reply.started":"2025-12-05T04:13:16.978511Z","shell.execute_reply":"2025-12-05T04:15:01.861306Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.53.3\nUninstalling transformers-4.53.3:\n  Successfully uninstalled transformers-4.53.3\nFound existing installation: accelerate 1.9.0\nUninstalling accelerate-1.9.0:\n  Successfully uninstalled accelerate-1.9.0\nFound existing installation: tokenizers 0.21.2\nUninstalling tokenizers-0.21.2:\n  Successfully uninstalled tokenizers-0.21.2\nFound existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Successfully uninstalled numpy-1.26.4\nCollecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntorchtune 0.6.1 requires tokenizers, which is not installed.\nkaggle-environments 1.18.0 requires transformers>=4.33.1, which is not installed.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\npeft 0.16.0 requires accelerate>=0.21.0, which is not installed.\npeft 0.16.0 requires transformers, which is not installed.\ndatasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4\nCollecting transformers\n  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting accelerate\n  Downloading accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\nCollecting tokenizers\n  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.8.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.4.1)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.18)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.15.2)\nCollecting pyarrow>=21.0.0 (from datasets>=2.0.0->evaluate)\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (0.28.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\nDownloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:01\u001b[0m\n\u001b[?25hDownloading accelerate-1.12.0-py3-none-any.whl (380 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, evaluate, accelerate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed accelerate-1.12.0 evaluate-0.4.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0 tokenizers-0.22.1 transformers-4.57.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy\nimport scipy\nprint(f\"Numpy version: {numpy.__version__}\")\nprint(f\"Scipy version: {scipy.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:01.863974Z","iopub.execute_input":"2025-12-05T04:15:01.864254Z","iopub.status.idle":"2025-12-05T04:15:01.885149Z","shell.execute_reply.started":"2025-12-05T04:15:01.864227Z","shell.execute_reply":"2025-12-05T04:15:01.884052Z"}},"outputs":[{"name":"stdout","text":"Numpy version: 1.26.4\nScipy version: 1.15.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom glob import glob\nfrom tqdm import tqdm\nimport time\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:01.886090Z","iopub.execute_input":"2025-12-05T04:15:01.887012Z","iopub.status.idle":"2025-12-05T04:15:09.343790Z","shell.execute_reply.started":"2025-12-05T04:15:01.886986Z","shell.execute_reply":"2025-12-05T04:15:09.343014Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Dataset Loader","metadata":{}},{"cell_type":"code","source":"ls /kaggle/input\n\nNUM_CLASSES = 10\nBATCH_SIZE = 16\nEPOCHS = 25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:09.345508Z","iopub.execute_input":"2025-12-05T04:15:09.345969Z","iopub.status.idle":"2025-12-05T04:15:09.485206Z","shell.execute_reply.started":"2025-12-05T04:15:09.345950Z","shell.execute_reply":"2025-12-05T04:15:09.484146Z"}},"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34mrescuenet-dataset\u001b[0m/\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import glob\ndef get_sorted_paths(folder_path):\n    files = sorted(glob.glob(os.path.join(folder_path, \"*\"))) \n    return files\n\nROOT_INP = \"/kaggle/input/rescuenet-dataset\"\n\ntrain_image_paths = get_sorted_paths(ROOT_INP+'/train/train-org-img')\ntrain_mask_paths = get_sorted_paths(ROOT_INP+'/train/train-label-img')\n\nval_image_paths = get_sorted_paths(ROOT_INP+'/val/val-org-img')\nval_mask_paths = get_sorted_paths(ROOT_INP+'/val/val-label-img')\n\ntest_image_paths = get_sorted_paths(ROOT_INP+'/test/test-org-img')\ntest_mask_paths = get_sorted_paths(ROOT_INP+'/test/test-label-img')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:09.486482Z","iopub.execute_input":"2025-12-05T04:15:09.486844Z","iopub.status.idle":"2025-12-05T04:15:09.704623Z","shell.execute_reply.started":"2025-12-05T04:15:09.486807Z","shell.execute_reply":"2025-12-05T04:15:09.703794Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class RescueNetDataset(Dataset):\n    def __init__(self, image_path, mask_path, transform=None, image_size=(512, 512)):\n        self.image_path = image_path\n        self.mask_path = mask_path\n        self.transform = transform\n        self.image_size = image_size\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_path[idx]).convert('RGB')\n        mask = Image.open(self.mask_path[idx]).convert('L')\n\n        if self.transform:\n            image = self.transform(image)\n\n        mask = mask.resize(self.image_size, Image.NEAREST)\n        mask = np.array(mask, dtype=np.int64)\n        # mask = np.clip(mask, 0, 9)\n        mask = torch.from_numpy(mask).long()\n\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:09.705707Z","iopub.execute_input":"2025-12-05T04:15:09.706501Z","iopub.status.idle":"2025-12-05T04:15:09.712343Z","shell.execute_reply.started":"2025-12-05T04:15:09.706471Z","shell.execute_reply":"2025-12-05T04:15:09.711565Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Dataset Prep","metadata":{}},{"cell_type":"code","source":"train_test_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n])\n\n# test_transform = transforms.Compose([\n#     transforms.Resize((512, 512)),\n#     transforms.ToTensor(),\n#     # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n# ])\n\n# Create dataset\ntrain_dataset = RescueNetDataset(train_image_paths, train_mask_paths, transform=train_test_transform)\nval_dataset = RescueNetDataset(val_image_paths, val_mask_paths, transform=train_test_transform)\ntest_dataset = RescueNetDataset(test_image_paths, test_mask_paths, transform=train_test_transform)\n\n# BATCH_SIZE = 2\n\n# Create Dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, drop_last=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:09.713443Z","iopub.execute_input":"2025-12-05T04:15:09.713870Z","iopub.status.idle":"2025-12-05T04:15:09.734511Z","shell.execute_reply.started":"2025-12-05T04:15:09.713850Z","shell.execute_reply":"2025-12-05T04:15:09.733708Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"from transformers import (Mask2FormerForUniversalSegmentation , Mask2FormerImageProcessor)\n\nmodel_id = \"facebook/mask2former-swin-large-ade-semantic\"\n\nprocessor = Mask2FormerImageProcessor.from_pretrained(\n    model_id, \n    ignore_index=255, \n    do_resize=False, \n    do_rescale=False)\n\nmodel = Mask2FormerForUniversalSegmentation.from_pretrained(\n    model_id,\n    num_labels=NUM_CLASSES, \n    ignore_mismatched_sizes=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:09.735325Z","iopub.execute_input":"2025-12-05T04:15:09.736329Z","iopub.status.idle":"2025-12-05T04:15:38.740367Z","shell.execute_reply.started":"2025-12-05T04:15:09.736301Z","shell.execute_reply":"2025-12-05T04:15:38.739497Z"}},"outputs":[{"name":"stderr","text":"2025-12-05 04:15:14.376755: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764908114.568683      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764908114.621573      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/538 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1acbf5f8a4543e7950366ba2de9bff5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"778b7e75812047fb96f093e692a880cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/866M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f53fc07d52e24355a7a09914cc546fd9"}},"metadata":{}},{"name":"stderr","text":"Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-large-ade-semantic and are newly initialized because the shapes did not match:\n- class_predictor.bias: found shape torch.Size([151]) in the checkpoint and torch.Size([12]) in the model instantiated\n- class_predictor.weight: found shape torch.Size([151, 256]) in the checkpoint and torch.Size([12, 256]) in the model instantiated\n- criterion.empty_weight: found shape torch.Size([151]) in the checkpoint and torch.Size([12]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Train n Eval","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)\nmodel.to(device)\nprint(f\"Model {model_id} siap untuk training 11 kelas RescueNet.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:38.741416Z","iopub.execute_input":"2025-12-05T04:15:38.742021Z","iopub.status.idle":"2025-12-05T04:15:39.206841Z","shell.execute_reply.started":"2025-12-05T04:15:38.741996Z","shell.execute_reply":"2025-12-05T04:15:39.205991Z"}},"outputs":[{"name":"stdout","text":"cuda\nModel facebook/mask2former-swin-large-ade-semantic siap untuk training 11 kelas RescueNet.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(f\"Train Images: {len(train_image_paths)}, Train Masks: {len(train_mask_paths)}\")\nprint(f\"Val Images: {len(val_image_paths)}, Val Masks: {len(val_mask_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:39.209228Z","iopub.execute_input":"2025-12-05T04:15:39.209537Z","iopub.status.idle":"2025-12-05T04:15:39.433574Z","shell.execute_reply.started":"2025-12-05T04:15:39.209518Z","shell.execute_reply":"2025-12-05T04:15:39.432817Z"}},"outputs":[{"name":"stdout","text":"Train Images: 3595, Train Masks: 3595\nVal Images: 449, Val Masks: 449\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nfrom torch.optim import AdamW\nfrom tqdm.auto import tqdm\nfrom torchmetrics import JaccardIndex\nfrom torch.optim.lr_scheduler import LambdaLR\nimport numpy as np\n\nval_iou_metric = JaccardIndex(\n    task=\"multiclass\",\n    num_classes=NUM_CLASSES,\n    ignore_index=255\n).to(device)\n\nbetas = (0.9, 0.999)\nweight_decay = 0.05\nlr=1e-5\n\n# EPOCHS = 6\n\noptimizer = AdamW(model.parameters(), \n                  # weight_decay=weight_decay, \n                  # betas=betas, \n                  lr=lr)\n\nbest_val_miou = 0.0  \nbest_epoch = -1\nglobal_iter = 0\n\nhistory = {\n    \"train_loss\": [],\n    \"val_loss\": [],\n    \"val_miou\": []\n}\n\nprint(\"ğŸš€ Mulai Training Mask2Former...\")\n\nfor epoch in range(EPOCHS):\n    \n    model.train()\n    \n    epoch_train_loss = 0.0\n    train_bar = tqdm(train_loader, desc=f\"[Train] Epoch {epoch+1}/{EPOCHS}\")\n\n    for images, masks in train_bar:\n\n        list_images = [img for img in images]\n        list_masks  = [m for m in masks]\n\n        inputs = processor(\n            images=list_images,\n            segmentation_maps=list_masks,\n            task_inputs=[\"semantic\"] * len(images),\n            return_tensors=\"pt\"\n        )\n\n        pixel_values = inputs[\"pixel_values\"].to(device)\n        mask_labels  = [m.to(device) for m in inputs[\"mask_labels\"]]\n        class_labels = [c.to(device) for c in inputs[\"class_labels\"]]\n\n        outputs = model(\n            pixel_values=pixel_values,\n            mask_labels=mask_labels,\n            class_labels=class_labels\n        )\n\n        loss = outputs.loss\n\n        optimizer.zero_grad()\n        loss.backward()\n\n        # torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n        \n        optimizer.step()\n        global_iter += 1\n        \n        epoch_train_loss += loss.item()\n        train_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n        del inputs, pixel_values, mask_labels, class_labels, outputs, loss\n        torch.cuda.empty_cache()\n        \n\n    avg_train_loss = epoch_train_loss / len(train_loader)\n    print(f\"ğŸ¯ Train Loss: {avg_train_loss:.4f}\")\n    history[\"train_loss\"].append(avg_train_loss)\n\n    # ----------------------------\n    # VALIDATION\n    # ----------------------------\n\n    model.eval()\n    val_iou_metric.reset()\n    epoch_val_loss = 0.0\n\n    val_bar = tqdm(val_loader, desc=f\"[Val] Epoch {epoch+1}/{EPOCHS}\")\n\n    with torch.no_grad():\n        for images, masks in val_bar:\n\n            list_images = [img for img in images]\n            list_masks  = [m for m in masks]\n\n            inputs = processor(\n                images=list_images,\n                segmentation_maps=list_masks,\n                task_inputs=[\"semantic\"] * len(images),\n                return_tensors=\"pt\"\n            )\n\n            pixel_values = inputs[\"pixel_values\"].to(device)\n            mask_labels  = [m.to(device) for m in inputs[\"mask_labels\"]]\n            class_labels = [c.to(device) for c in inputs[\"class_labels\"]]\n\n            outputs = model(\n                pixel_values=pixel_values,\n                mask_labels=mask_labels,\n                class_labels=class_labels\n            )\n\n            loss = outputs.loss\n            epoch_val_loss += loss.item()\n\n            target_sizes = [(m.shape[0], m.shape[1]) for m in masks]\n            preds = processor.post_process_semantic_segmentation(\n                outputs, target_sizes=target_sizes\n            )\n\n            preds_tensor  = torch.stack(preds).to(device)\n            target_tensor = masks.to(device)\n\n            val_iou_metric.update(preds_tensor, target_tensor)\n\n            del inputs, outputs, loss\n            torch.cuda.empty_cache()\n\n    avg_val_loss = epoch_val_loss / len(val_loader)\n    val_miou = val_iou_metric.compute().mean().item()\n    val_iou_metric.reset()\n    \n    print(f\"ğŸ“Œ Val Loss: {avg_val_loss:.4f} | Val mIoU: {val_miou:.4f}\")\n    print(\"-\" * 50)\n\n    history[\"val_loss\"].append(avg_val_loss)\n    history[\"val_miou\"].append(val_miou)\n\n    if val_miou > best_val_miou:\n        best_val_miou = val_miou\n        best_epoch = epoch + 1\n        torch.save(model.state_dict(), \"best_model_mask2former_lokal.pth\")\n        print(f\"ğŸ’¾ New best model ! Epoch {epoch+1}, mIoU={val_miou:.4f}\")\n\nprint(f\"\\nTraining Done Om! Best model in epoch {best_epoch} with mIoU={best_val_miou:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:16:05.499122Z","iopub.execute_input":"2025-12-05T04:16:05.499778Z","iopub.status.idle":"2025-12-05T07:47:23.400343Z","shell.execute_reply.started":"2025-12-05T04:16:05.499751Z","shell.execute_reply":"2025-12-05T07:47:23.398315Z"}},"outputs":[{"name":"stdout","text":"ğŸš€ Mulai Training Mask2Former...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Train] Epoch 1/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fedd46ddfd5b431d9f87f33378b7044c"}},"metadata":{}},{"name":"stdout","text":"ğŸ¯ Train Loss: 39.5014\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Val] Epoch 1/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"655afbb77c614f5b93c7e8829ddee752"}},"metadata":{}},{"name":"stdout","text":"ğŸ“Œ Val Loss: 31.1909 | Val mIoU: 0.5673\n--------------------------------------------------\nğŸ’¾ New best model ! Epoch 1, mIoU=0.5673\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Train] Epoch 2/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f639c4dfe64f2ca8a8d7101ce859f6"}},"metadata":{}},{"name":"stdout","text":"ğŸ¯ Train Loss: 29.6824\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Val] Epoch 2/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0dfe7c285c9c40cf88617d24584c58b9"}},"metadata":{}},{"name":"stdout","text":"ğŸ“Œ Val Loss: 27.5804 | Val mIoU: 0.5891\n--------------------------------------------------\nğŸ’¾ New best model ! Epoch 2, mIoU=0.5891\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Train] Epoch 3/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75937ea0d5944ba5abc428487f405564"}},"metadata":{}},{"name":"stdout","text":"ğŸ¯ Train Loss: 25.6456\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Val] Epoch 3/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4624d944f17b4d64951dc8019974f005"}},"metadata":{}},{"name":"stdout","text":"ğŸ“Œ Val Loss: 25.4528 | Val mIoU: 0.6102\n--------------------------------------------------\nğŸ’¾ New best model ! Epoch 3, mIoU=0.6102\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Train] Epoch 4/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c5cea12842e47f6bc5d9dfb5e564514"}},"metadata":{}},{"name":"stdout","text":"ğŸ¯ Train Loss: 23.0581\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Val] Epoch 4/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5741a6aec4174328bea42e24bf1377f6"}},"metadata":{}},{"name":"stdout","text":"ğŸ“Œ Val Loss: 24.4161 | Val mIoU: 0.6188\n--------------------------------------------------\nğŸ’¾ New best model ! Epoch 4, mIoU=0.6188\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Train] Epoch 5/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d41c63483934fa4a8f7354118d2fd3d"}},"metadata":{}},{"name":"stdout","text":"ğŸ¯ Train Loss: 20.8601\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Val] Epoch 5/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"889170bb047946c6a5a0b2ee4054c30b"}},"metadata":{}},{"name":"stdout","text":"ğŸ“Œ Val Loss: 23.8408 | Val mIoU: 0.6228\n--------------------------------------------------\nğŸ’¾ New best model ! Epoch 5, mIoU=0.6228\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Train] Epoch 6/6:   0%|          | 0/1797 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40e1ea25fd3942ff8fbc2cfcfee2a1ec"}},"metadata":{}},{"name":"stdout","text":"ğŸ¯ Train Loss: 19.2240\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[Val] Epoch 6/6:   0%|          | 0/224 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"878ba761474b4a08bf54a184f2622b50"}},"metadata":{}},{"name":"stdout","text":"ğŸ“Œ Val Loss: 23.5657 | Val mIoU: 0.6366\n--------------------------------------------------\nğŸ’¾ New best model ! Epoch 6, mIoU=0.6366\n\nTraining Done Om! Best model in epoch 6 with mIoU=0.6366\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import json \n\nWORKDIR = \"/kaggle/working\"\noutput_path = WORKDIR + \"/history_mask2former_lokal.json\"\n\nwith open(output_path, \"w\") as f:\n    json.dump(history, f, indent=4)\n\nprint(\"File saved to:\", output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:48:32.178132Z","iopub.execute_input":"2025-12-05T07:48:32.179609Z","iopub.status.idle":"2025-12-05T07:48:32.187201Z","shell.execute_reply.started":"2025-12-05T07:48:32.179568Z","shell.execute_reply":"2025-12-05T07:48:32.186456Z"}},"outputs":[{"name":"stdout","text":"File saved to: /kaggle/working/history_mask2former.json\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"import torch\nfrom tqdm.auto import tqdm\nfrom torchmetrics import JaccardIndex  \n\ndef test_model(model, test_loader, device, processor):\n    metric = JaccardIndex(\n        task=\"multiclass\", \n        num_classes=NUM_CLASSES, \n        ignore_index=255,\n        average=\"none\" \n    ).to(device)\n\n    model.to(device)\n    \n    model.eval()\n    print(\"Mulai Testing (menggunakan JaccardIndex)...\")\n    \n    with torch.no_grad():\n        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n            list_images = [img for img in images]\n            \n            inputs = processor(\n                images=list_images,\n                return_tensors=\"pt\",\n                do_resize=False,   \n                do_rescale=False   \n            )\n            inputs = {k: v.to(device) for k, v in inputs.items()}\n            \n            outputs = model(**inputs)\n            \n            target_sizes = [(m.shape[0], m.shape[1]) for m in masks]\n            pred_maps = processor.post_process_semantic_segmentation(\n                outputs, target_sizes=target_sizes\n            )\n            preds_batch = torch.stack(pred_maps).to(device)\n            target_batch = masks.to(device)\n            \n            metric.update(preds_batch, target_batch)\n    \n    iou_per_class = metric.compute()\n    \n    mIoU = iou_per_class.mean().item()\n    \n    print(\"\\n=== HASIL TESTING ===\")\n    print(f\"Mean IoU (mIoU): {mIoU:.4f}\")\n    print(\"-\" * 30)\n    \n    class_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n                   \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n    \n    for i, iou in enumerate(iou_per_class):\n        name = class_names[i] if i < len(class_names) else f\"Class {i}\"\n        print(f\"{name:25s}: {iou.item():.4f}\")\n        \n    metric.reset()\n    return mIoU, iou_per_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:48:34.256783Z","iopub.execute_input":"2025-12-05T07:48:34.257400Z","iopub.status.idle":"2025-12-05T07:48:34.266051Z","shell.execute_reply.started":"2025-12-05T07:48:34.257377Z","shell.execute_reply":"2025-12-05T07:48:34.265238Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch\nfrom transformers import Mask2FormerForUniversalSegmentation, Mask2FormerImageProcessor\n\nmodel_id = \"facebook/mask2former-swin-large-ade-semantic\"\nWORKDIR = \"/kaggle/working\"\n\nclass_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n               \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n    \n# num_labels = len(class_names)            \n# num_classes_internal = num_labels + 1    \n\nprocessor = Mask2FormerImageProcessor.from_pretrained(\n    model_id,\n    ignore_index=255,\n    do_resize=False,\n    do_rescale=False\n)\n\nmodel = Mask2FormerForUniversalSegmentation.from_pretrained(\n    model_id,\n    num_labels=NUM_CLASSES,\n    ignore_mismatched_sizes=True\n)\n\nckpt = torch.load(WORKDIR + \"/best_model_mask2former_lokal.pth\", map_location=\"cpu\")\n\nif isinstance(ckpt, dict) and \"model\" in ckpt:\n    ckpt_state = ckpt[\"model\"]\nelse:\n    ckpt_state = ckpt\n\nmodel_state = model.state_dict()\ncompatible = {k: v for k, v in ckpt_state.items() if (k in model_state and v.shape == model_state[k].shape)}\n\nprint(f\"Total model keys: {len(model_state)}; Compatible keys from ckpt: {len(compatible)}; Skipped keys: {len(ckpt_state)-len(compatible)}\")\n\nmodel_state.update(compatible)\nmodel.load_state_dict(model_state)\n\ntest_mIoU, test_iou_per_class = test_model(model, test_loader, device, processor)\n\n# print(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\n# print(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\n# print(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\n# print(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\")\n# print(f\"===================== Hasil Testing mIoU {test_mIoU} ========================\\n\\n\\n\")\n# print(f\"===================== IoU Per Class ========================\")\n# for i, iou in enumerate(test_iou_per_class):\n#         name = class_names[i] if i < len(class_names) else f\"Class {i}\"\n#         print(f\"{name:25s}: {iou.item():.4f}\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T07:48:36.832143Z","iopub.execute_input":"2025-12-05T07:48:36.832439Z","iopub.status.idle":"2025-12-05T07:50:03.804305Z","shell.execute_reply.started":"2025-12-05T07:48:36.832416Z","shell.execute_reply":"2025-12-05T07:50:03.803346Z"}},"outputs":[{"name":"stderr","text":"Some weights of Mask2FormerForUniversalSegmentation were not initialized from the model checkpoint at facebook/mask2former-swin-large-ade-semantic and are newly initialized because the shapes did not match:\n- class_predictor.bias: found shape torch.Size([151]) in the checkpoint and torch.Size([12]) in the model instantiated\n- class_predictor.weight: found shape torch.Size([151, 256]) in the checkpoint and torch.Size([12, 256]) in the model instantiated\n- criterion.empty_weight: found shape torch.Size([151]) in the checkpoint and torch.Size([12]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Total model keys: 782; Compatible keys from ckpt: 782; Skipped keys: 0\nMulai Testing (menggunakan JaccardIndex)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/225 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3c5027791d94d1a89d8070165f9f213"}},"metadata":{}},{"name":"stdout","text":"\n=== HASIL TESTING ===\nMean IoU (mIoU): 0.6338\n------------------------------\nBackground               : 0.8335\nWater                    : 0.7996\nBuilding No Damage       : 0.5772\nBuilding Minor Damage    : 0.5108\nBuilding Major Damage    : 0.4606\nBuilding Total Destruction: 0.6075\nRoad-Clear               : 0.6141\nRoad-Blocked             : 0.7319\nVehicle                  : 0.3436\nTree                     : 0.7914\nPool                     : 0.7011\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# import torch\n# import os\n# from matplotlib.patches import Patch\n\n# CLASS_NAMES = [\n#     \"Background\",               \n#     \"Water\",                    \n#     \"Building No Damage\",       \n#     \"Building Minor Damage\",    \n#     \"Building Major Damage\",    \n#     \"Building Total Destruction\",\n#     \"Road-Clear\",               \n#     \"Road-Blocked\",             \n#     \"Vehicle\",                  \n#     \"Tree\",                     \n#     \"Pool\"                      \n# ]\n\n# LABEL_COLORS = np.array([\n#     [0, 0, 0],         # Background \n#     [30, 230, 255],    # Water \n#     [184, 115, 117],   # Building No Damage\n#     [216, 255, 0],     # Building Minor Damage\n#     [252, 199, 0],     # Building Major Damage\n#     [255, 0, 0],       # Building Total Destruction\n#     [140, 140, 140],   # Road-Clear\n#     [151, 0, 255],     # Road-Blocked\n#     [255, 0, 246],     # Vehicle \n#     [0, 255, 0],       # Tree\n#     [244, 255, 0]      # Pool\n# ])\n# def decode_segmap(mask):\n#     r = np.zeros_like(mask).astype(np.uint8)\n#     g = np.zeros_like(mask).astype(np.uint8)\n#     b = np.zeros_like(mask).astype(np.uint8)\n    \n#     for l in range(0, len(LABEL_COLORS)):\n#         idx = mask == l\n#         r[idx] = LABEL_COLORS[l, 0]\n#         g[idx] = LABEL_COLORS[l, 1]\n#         b[idx] = LABEL_COLORS[l, 2]\n        \n#     rgb = np.stack([r, g, b], axis=2)\n#     return rgb\n\n# def find_indices_by_filename(dataset, target_ids):\n#     found_indices = []\n#     for target in target_ids:\n#         found = False\n#         for idx, path in enumerate(dataset.image_path):\n#             if str(target) in os.path.basename(path):\n#                 found_indices.append(idx)\n#                 found = True\n#                 break\n#         if not found:\n#             return \n#     return found_indices\n\n# def visualize_specific_images(model, dataset, target_ids, device, processor):\n#     model.eval()\n    \n#     indices = find_indices_by_filename(dataset, target_ids)\n\n#     num_samples = len(indices)\n#     fig, axes = plt.subplots(num_samples, 3, figsize=(18, 6 * num_samples))\n    \n#     if num_samples == 1:\n#         axes = axes.reshape(1, -1)\n\n#     for row_idx, idx in enumerate(indices):\n#         image, mask = dataset[idx] \n        \n#         filename = os.path.basename(dataset.image_path[idx])\n        \n#         inputs = processor(\n#             images=[image], \n#             return_tensors=\"pt\",\n#             do_resize=False, \n#             do_rescale=False\n#         )\n#         inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n#         with torch.no_grad():\n#             outputs = model(**inputs)\n        \n#         target_sizes = [(mask.shape[0], mask.shape[1])]\n#         pred_map = processor.post_process_semantic_segmentation(\n#             outputs, target_sizes=target_sizes\n#         )[0] \n        \n#         img_np = image.permute(1, 2, 0).numpy()\n        \n#         mask_rgb = decode_segmap(mask.numpy())\n#         pred_rgb = decode_segmap(pred_map.cpu().numpy())\n        \n#         axes[row_idx, 0].imshow(img_np)\n#         axes[row_idx, 0].set_title(f\"ID: {filename}\\nOriginal Image\")\n#         axes[row_idx, 0].axis(\"off\")\n        \n#         axes[row_idx, 1].imshow(mask_rgb)\n#         axes[row_idx, 1].set_title(\"Ground Truth\")\n#         axes[row_idx, 1].axis(\"off\")\n        \n#         axes[row_idx, 2].imshow(pred_rgb)\n#         axes[row_idx, 2].set_title(\"Mask2Former Prediction\")\n#         axes[row_idx, 2].axis(\"off\")\n\n#     handles = [Patch(color=LABEL_COLORS[i]/255.0, label=CLASS_NAMES[i]) for i in range(len(CLASS_NAMES))]\n#     fig.legend(handles=handles, loc='lower center', ncol=6, bbox_to_anchor=(0.5, 0.0), fontsize=12)\n\n#     plt.savefig('visualisasi_prediksi_rescuenet.png', bbox_inches='tight', dpi=300)\n    \n#     plt.tight_layout()\n#     plt.subplots_adjust(bottom=0.08) \n#     plt.show()\n\n# target_ids = [\"10794\", \"10801\", \"10807\"]\n\n# visualize_specific_images(model, test_dataset, target_ids, device, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:39.456676Z","iopub.status.idle":"2025-12-05T04:15:39.456977Z","shell.execute_reply.started":"2025-12-05T04:15:39.456850Z","shell.execute_reply":"2025-12-05T04:15:39.456865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.eval()\n# import matplotlib.pyplot as plt\n\n# test_imgs, test_masks = next(iter(test_loader))\n\n# with torch.no_grad():\n#     inputs = [{\"image\": test_imgs[0].to(cfg.MODEL.DEVICE), \"height\": 512, \"width\": 512}]\n    \n#     outputs = model(inputs)\n    \n#     pred_mask = outputs[0][\"sem_seg\"].argmax(dim=0).cpu().numpy()\n\n# plt.figure(figsize=(10, 5))\n# plt.subplot(1, 2, 1); plt.title(\"Prediction\"); plt.imshow(pred_mask)\n# plt.subplot(1, 2, 2); plt.title(\"Ground Truth\"); plt.imshow(test_masks[0])\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T04:15:39.458179Z","iopub.status.idle":"2025-12-05T04:15:39.458521Z","shell.execute_reply.started":"2025-12-05T04:15:39.458348Z","shell.execute_reply":"2025-12-05T04:15:39.458364Z"}},"outputs":[],"execution_count":null}]}