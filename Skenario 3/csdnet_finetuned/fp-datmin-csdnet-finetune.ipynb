{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12690938,"sourceType":"datasetVersion","datasetId":8020112},{"sourceId":674895,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":511571,"modelId":526238}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install timm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:29:59.197080Z","iopub.execute_input":"2025-12-07T02:29:59.197961Z","iopub.status.idle":"2025-12-07T02:30:02.483766Z","shell.execute_reply.started":"2025-12-07T02:29:59.197928Z","shell.execute_reply":"2025-12-07T02:30:02.483022Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (25.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.5)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.2.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->timm) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->timm) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->timm) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->timm) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->timm) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom glob import glob\nfrom tqdm import tqdm\nimport time\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as T\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:02.485434Z","iopub.execute_input":"2025-12-07T02:30:02.485670Z","iopub.status.idle":"2025-12-07T02:30:02.490954Z","shell.execute_reply.started":"2025-12-07T02:30:02.485646Z","shell.execute_reply":"2025-12-07T02:30:02.490403Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Dataset Loader","metadata":{}},{"cell_type":"code","source":"!ls /kaggle/input\n\nNUM_CLASSES = 10\nBATCH_SIZE = 4\nEPOCHS = 25\n\nMODEL_NAME = \"best_model_csdnet.pth\"\nMODEL_NAME_FINETUNED = \"best_model_csdnet_finetuned.pth\"\nDIR_MODEL = \"/kaggle/input/csdnet/pytorch/default/1/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:02.491897Z","iopub.execute_input":"2025-12-07T02:30:02.492117Z","iopub.status.idle":"2025-12-07T02:30:02.635686Z","shell.execute_reply.started":"2025-12-07T02:30:02.492099Z","shell.execute_reply":"2025-12-07T02:30:02.634972Z"}},"outputs":[{"name":"stdout","text":"csdnet\tindo-flood-segmentation-dataset\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import glob\nimport re\ndef sort_files_numerically(directory):\n    files = os.listdir(directory)\n    files_sorted = sorted(files, key=lambda x: int(re.search(r'\\d+', x).group()))\n    return [os.path.join(directory, f) for f in files_sorted]\n\nROOT_INP = \"/kaggle/input/indo-flood-segmentation-dataset\"\n\ntrain_image_paths = sort_files_numerically(ROOT_INP+'/train/train-org-img')\ntrain_mask_paths = sort_files_numerically(ROOT_INP+'/train/train-label-img')\n\nval_image_paths = sort_files_numerically(ROOT_INP+'/val/val-org-img')\nval_mask_paths = sort_files_numerically(ROOT_INP+'/val/val-label-img')\n\ntest_image_paths = sort_files_numerically(ROOT_INP+'/test/test-org-img')\ntest_mask_paths = sort_files_numerically(ROOT_INP+'/test/test-label-img')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:02.636663Z","iopub.execute_input":"2025-12-07T02:30:02.637023Z","iopub.status.idle":"2025-12-07T02:30:02.681145Z","shell.execute_reply.started":"2025-12-07T02:30:02.636992Z","shell.execute_reply":"2025-12-07T02:30:02.680429Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class FloodDataset(Dataset):\n    def __init__(self, image_path, mask_path, transform=None, image_size=(512, 512)):\n        self.image_path = image_path\n        self.mask_path = mask_path\n        self.transform = transform\n        self.image_size = image_size\n\n    def __len__(self):\n        return len(self.image_path)\n\n    def __getitem__(self, idx):\n        image = Image.open(self.image_path[idx]).convert('RGB')\n        mask = Image.open(self.mask_path[idx]).convert('L')\n\n        if self.transform:\n            image = self.transform(image)\n\n        mask = mask.resize(self.image_size, Image.NEAREST)\n        mask = np.array(mask, dtype=np.int64)\n        mask = np.clip(mask, 0, 9)\n        mask = torch.from_numpy(mask).long()\n\n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:02.682952Z","iopub.execute_input":"2025-12-07T02:30:02.683214Z","iopub.status.idle":"2025-12-07T02:30:02.689062Z","shell.execute_reply.started":"2025-12-07T02:30:02.683173Z","shell.execute_reply":"2025-12-07T02:30:02.688431Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Dataset Prep","metadata":{}},{"cell_type":"code","source":"train_test_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = FloodDataset(train_image_paths, train_mask_paths, transform=train_test_transform)\nval_dataset = FloodDataset(val_image_paths, val_mask_paths, transform=train_test_transform)\ntest_dataset = FloodDataset(test_image_paths, test_mask_paths, transform=train_test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:02.689817Z","iopub.execute_input":"2025-12-07T02:30:02.690413Z","iopub.status.idle":"2025-12-07T02:30:02.704981Z","shell.execute_reply.started":"2025-12-07T02:30:02.690396Z","shell.execute_reply":"2025-12-07T02:30:02.704352Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# def get_all_unique_masks(dataloader, max_batches=None):\n#     all_unique = set()\n#     for i, (_, masks) in enumerate(dataloader):\n#         all_unique.update(int(u) for u in torch.unique(masks))\n#         if max_batches is not None and i+1 >= max_batches:\n#             break\n#     return sorted(all_unique)\n\n# # print(\"Train unique (scan 200 batches):\", get_all_unique_masks(train_loader, max_batches=200))\n# # print(\"Val unique   (scan all):       \", get_all_unique_masks(val_loader))\n# print(\"Test unique  (scan all):       \", get_all_unique_masks(test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:02.705664Z","iopub.execute_input":"2025-12-07T02:30:02.705887Z","iopub.status.idle":"2025-12-07T02:30:02.720268Z","shell.execute_reply.started":"2025-12-07T02:30:02.705872Z","shell.execute_reply":"2025-12-07T02:30:02.719538Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Modelling","metadata":{}},{"cell_type":"code","source":"import timm\n\nclass DWSC(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n        super().__init__()\n        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, stride, \n                                   padding, groups=in_channels, bias=False)\n        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.depthwise(x)\n        x = self.pointwise(x)\n        x = self.bn(x)\n        return self.relu(x)\n\nclass ASPP(nn.Module):\n    def __init__(self, in_channels, out_channels=256):\n        super().__init__()\n        dilations = [1, 6, 12, 18]\n        self.aspp_blocks = nn.ModuleList()\n        \n        self.aspp_blocks.append(nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        ))\n\n        for dilation in dilations[1:]:\n            self.aspp_blocks.append(nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 3, padding=dilation, dilation=dilation, bias=False),\n                nn.BatchNorm2d(out_channels),\n                nn.ReLU(inplace=True)\n            ))\n\n        self.global_pool = nn.Sequential(\n            nn.AdaptiveAvgPool2d((1, 1)),\n            nn.Conv2d(in_channels, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        self.project = nn.Sequential(\n            nn.Conv2d(out_channels * 5, out_channels, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5)\n        )\n\n    def forward(self, x):\n        res = []\n        for block in self.aspp_blocks:\n            res.append(block(x))\n        \n        g = self.global_pool(x)\n        g = F.interpolate(g, size=x.shape[2:], mode='bilinear', align_corners=False)\n        res.append(g)\n        \n        res = torch.cat(res, dim=1)\n        return self.project(res)\n\nclass TargetedEnhancementModule(nn.Module):\n    def __init__(self, f1_channels, detector_channels=256, fusion_dim=256):\n        super().__init__()\n        self.aspp_f1 = ASPP(f1_channels, fusion_dim)\n        \n        self.phi = nn.Sequential(\n            nn.Conv2d(detector_channels, fusion_dim, 1),\n            nn.BatchNorm2d(fusion_dim),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, f1, f_det):\n        \n        f1_processed = self.aspp_f1(f1)\n        \n        f_det_processed = self.phi(f_det)\n        f_det_resized = F.interpolate(f_det_processed, size=f1_processed.shape[2:], \n                                      mode='bilinear', align_corners=False)\n        \n        return f1_processed * f_det_resized\n\nclass DeepContextualAttention(nn.Module):\n    def __init__(self, in_channels, dim=256):\n        super().__init__()\n        self.dwsc_in = DWSC(in_channels, dim)\n        \n        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=4, dim_feedforward=dim*2, batch_first=True)\n        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n        \n        self.aspp = ASPP(dim, dim)\n\n    def forward(self, x):\n        B, C, H, W = x.shape\n        \n        x = self.dwsc_in(x) # (B, dim, H, W)\n        \n        tokens = x.flatten(2).transpose(1, 2)\n        \n        tokens = self.transformer(tokens)\n        \n        x_trans = tokens.transpose(1, 2).view(B, -1, H, W)\n        \n        x_out = self.aspp(x_trans)\n        \n        return x_out\n\nclass MultiScaleFusion(nn.Module):\n    def __init__(self, f2_channels, f3_channels, out_dim=256):\n        super().__init__()\n        self.psi2 = nn.Conv2d(f2_channels, out_dim, 1)\n        self.psi3 = nn.Conv2d(f3_channels, out_dim, 1)\n        \n        self.fusion_conv = nn.Sequential(\n            nn.Conv2d(out_dim * 2, out_dim, 3, padding=1, bias=False),\n            nn.BatchNorm2d(out_dim),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, f2, f3):\n        f2_hat = self.psi2(f2)\n        f3_hat = self.psi3(f3)\n        \n        f3_hat_up = F.interpolate(f3_hat, size=f2_hat.shape[2:], mode='bilinear', align_corners=False)\n        \n        f_gen = torch.cat([f2_hat, f3_hat_up], dim=1)\n        return self.fusion_conv(f_gen)\n\nclass CSDNet(nn.Module):\n    def __init__(self, num_classes=NUM_CLASSES):\n        super().__init__()\n        \n        self.encoder = timm.create_model(\n            \"efficientnet_b5\",\n            pretrained=True,\n            features_only=True,\n            out_indices=(0, 1, 2, 3) \n        )\n        \n        dims = self.encoder.feature_info.channels() \n        f1_c, f2_c, f3_c, f4_c = dims[0], dims[1], dims[2], dims[3]\n        \n        fusion_dim = 128 \n        \n        self.mod1_detection = TargetedEnhancementModule(f1_c, detector_channels=256, fusion_dim=fusion_dim)\n        \n        self.mod2_transformer = DeepContextualAttention(f4_c, dim=fusion_dim)\n        \n        self.mod3_cnn = MultiScaleFusion(f2_c, f3_c, out_dim=fusion_dim)\n        \n        self.classifier = nn.Sequential(\n            nn.Conv2d(fusion_dim * 3, 256, 3, padding=1, bias=False),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.1),\n            nn.Conv2d(256, num_classes, 1)\n        )\n        \n        self.detector_dummy_layer = nn.Conv2d(3, 256, kernel_size=32, stride=32) \n\n    def get_detection_features(self, x):\n        with torch.no_grad(): \n            det_feats = self.detector_dummy_layer(x) \n        return det_feats\n\n    def forward(self, x):\n        input_shape = x.shape[2:]\n        \n        feats = self.encoder(x)\n        f1, f2, f3, f4 = feats[0], feats[1], feats[2], feats[3]\n        \n        f_det_raw = self.get_detection_features(x)\n        \n        feat_branch1 = self.mod1_detection(f1, f_det_raw) \n        \n        feat_branch2 = self.mod2_transformer(f4)\n        \n        feat_branch3 = self.mod3_cnn(f2, f3)\n        \n        target_size = feat_branch1.shape[2:]\n        \n        feat_branch2_up = F.interpolate(feat_branch2, size=target_size, mode='bilinear', align_corners=False)\n        feat_branch3_up = F.interpolate(feat_branch3, size=target_size, mode='bilinear', align_corners=False)\n        \n        f_final = torch.cat([feat_branch1, feat_branch2_up, feat_branch3_up], dim=1)\n        \n        logits = self.classifier(f_final)\n        \n        logits = F.interpolate(logits, size=input_shape, mode='bilinear', align_corners=False)\n        \n        return logits\n\n# model = CSDNet(num_classes=NUM_CLASSES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:02.721098Z","iopub.execute_input":"2025-12-07T02:30:02.721437Z","iopub.status.idle":"2025-12-07T02:30:06.237341Z","shell.execute_reply.started":"2025-12-07T02:30:02.721415Z","shell.execute_reply":"2025-12-07T02:30:06.236704Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Train n Eval","metadata":{}},{"cell_type":"code","source":"print(f\"Train Images: {len(train_image_paths)}, Train Masks: {len(train_mask_paths)}\")\nprint(f\"Val Images: {len(val_image_paths)}, Val Masks: {len(val_mask_paths)}\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"DEVICE USED : {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:06.238080Z","iopub.execute_input":"2025-12-07T02:30:06.238308Z","iopub.status.idle":"2025-12-07T02:30:06.302814Z","shell.execute_reply.started":"2025-12-07T02:30:06.238291Z","shell.execute_reply":"2025-12-07T02:30:06.301843Z"}},"outputs":[{"name":"stdout","text":"Train Images: 116, Train Masks: 116\nVal Images: 14, Val Masks: 14\nDEVICE USED : cuda\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"model = CSDNet(num_classes=NUM_CLASSES)\n\nWEIGHTS_PATH = DIR_MODEL + MODEL_NAME\n\nif os.path.exists(WEIGHTS_PATH):\n    print(f\"Loading weights from: {WEIGHTS_PATH}\")\n    checkpoint = torch.load(WEIGHTS_PATH, map_location=\"cpu\")\n    \n    if 'state_dict' in checkpoint:\n        state_dict = checkpoint['state_dict']\n    elif 'model' in checkpoint:\n        state_dict = checkpoint['model']\n    else:\n        state_dict = checkpoint\n\n    new_state_dict = {}\n    \n    for key, value in state_dict.items():\n        if \"classifier.4\" in key:\n            print(f\"Skipping weight: {key} (Shape mismatch expected: Old vs New classes)\")\n            continue\n            \n        new_state_dict[key] = value\n\n    msg = model.load_state_dict(new_state_dict, strict=False)\n    \n    print(\"\\nStatus Load Model:\")\n    print(msg) \n\n    \nelse:\n    print(f\"Warning: File {WEIGHTS_PATH} tidak ditemukan.\")\n    \nmodel.to(device)\n\nlast_layer = model.classifier[4]\nprint(f\"\\nVerifikasi Output Layer: {last_layer.out_channels} channels (Harus sama dengan {NUM_CLASSES})\")\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2.0, alpha=None, ignore_index=255):\n        super().__init__()\n        self.gamma = gamma\n        self.ce = nn.CrossEntropyLoss(reduction='none', weight=alpha, ignore_index=ignore_index)\n\n    def forward(self, logits, targets):\n        ce_loss = self.ce(logits, targets) \n        pt = torch.exp(-ce_loss)\n        focal_loss = (1 - pt) ** self.gamma * ce_loss\n        return focal_loss.mean() \n\n\nclass JaccardLoss(nn.Module):\n    def __init__(self, eps=1e-7):\n        super().__init__()\n        self.eps = eps\n\n    def forward(self, logits, targets):\n        num_classes = logits.shape[1]\n        preds = torch.softmax(logits, dim=1)\n\n        target_1hot = torch.nn.functional.one_hot(targets, num_classes).permute(0,3,1,2)\n\n        intersection = (preds * target_1hot).sum(dim=(2,3))\n        union = preds.sum(dim=(2,3)) + target_1hot.sum(dim=(2,3)) - intersection\n\n        iou = (intersection + self.eps) / (union + self.eps)\n        return 1 - iou.mean()\n\n\nfocal_loss = FocalLoss(gamma=2.0)\njaccard_loss = JaccardLoss()\n\n\ndef total_loss_fn(pred, target):\n    return focal_loss(pred, target) + jaccard_loss(pred, target)\n\noptimizer = torch.optim.SGD(\n    model.parameters(),\n    lr=0.01,\n    momentum=0.9,\n    weight_decay=1e-4\n)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode='min',\n    patience=10,\n    factor=0.1,\n    min_lr=1e-4\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:46.201147Z","iopub.execute_input":"2025-12-07T02:30:46.201897Z","iopub.status.idle":"2025-12-07T02:30:47.078801Z","shell.execute_reply.started":"2025-12-07T02:30:46.201875Z","shell.execute_reply":"2025-12-07T02:30:47.078152Z"}},"outputs":[{"name":"stderr","text":"Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n","output_type":"stream"},{"name":"stdout","text":"Loading weights from: /kaggle/input/csdnet/pytorch/default/1/best_model_csdnet.pth\nSkipping weight: classifier.4.weight (Shape mismatch expected: Old vs New classes)\nSkipping weight: classifier.4.bias (Shape mismatch expected: Old vs New classes)\n\nStatus Load Model:\n_IncompatibleKeys(missing_keys=['classifier.4.weight', 'classifier.4.bias'], unexpected_keys=[])\n\nVerifikasi Output Layer: 10 channels (Harus sama dengan 10)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from torchmetrics import JaccardIndex\nfrom tqdm.auto import tqdm\n\nmetric_val   = JaccardIndex(task=\"multiclass\", num_classes=NUM_CLASSES, average=None).to(device)\n\nbest_mIoU = 0.0\n\nhistory = {\n    \"train_loss\": [],\n    \"val_loss\": [],\n    \"val_miou\": []\n}\n\nfor epoch in range(EPOCHS):\n\n    model.train()\n    train_loss = 0\n    \n    if hasattr(model, 'detector_dummy_layer'):\n        model.detector_dummy_layer.eval()\n\n    for images, masks in tqdm(train_loader, desc=f\"Train {epoch+1}/{EPOCHS}\"):\n        images, masks = images.to(device), masks.to(device)\n\n        optimizer.zero_grad()\n        preds = model(images)\n        loss = total_loss_fn(preds, masks)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    train_loss /= len(train_loader)\n\n    print(f\"ðŸŽ¯ Train Loss: {train_loss:.4f}\")\n    history[\"train_loss\"].append(train_loss)\n\n    model.eval()\n    val_loss = 0\n    metric_val.reset()\n\n    with torch.no_grad():\n        for images, masks in tqdm(val_loader, desc=f\"Val {epoch+1}/{EPOCHS}\"):\n            images, masks = images.to(device), masks.to(device)\n\n            preds = model(images)\n            loss = total_loss_fn(preds, masks)\n            val_loss += loss.item()\n\n            pred_mask = preds.argmax(dim=1)\n            metric_val.update(pred_mask, masks)\n\n    val_loss /= len(val_loader)\n    iou_val_per_class = metric_val.compute()\n    mIoU_val = iou_val_per_class.mean().item()\n\n    history[\"val_loss\"].append(val_loss)\n    history[\"val_miou\"].append(mIoU_val)\n\n    print(f\"\"\"\n============================== Epoch: {epoch+1}/{EPOCHS}\nTrain Loss: {train_loss:.4f}\nVal Loss:   {val_loss:.4f}   | Val mIoU: {mIoU_val:.4f}\n==============================\n\"\"\")\n\n\n    scheduler.step(val_loss)\n\n    if best_mIoU < mIoU_val:\n        best_mIoU = mIoU_val\n        torch.save(model.state_dict(), \"best_model_csdnet_finetuned.pth\")\n        print(\"Model disimpan (best so far).\")\n            \nprint(\"Training Selesai!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:31:57.983067Z","iopub.execute_input":"2025-12-07T02:31:57.983674Z","iopub.status.idle":"2025-12-07T02:46:58.677440Z","shell.execute_reply.started":"2025-12-07T02:31:57.983648Z","shell.execute_reply":"2025-12-07T02:46:58.676763Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Train 1/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb95de4a0af44a35af0e5024b97647c6"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 2.0518\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 1/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed4d0f04334142bdaa75b8c60d098bf1"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 1/25\nTrain Loss: 2.0518\nVal Loss:   1.5756   | Val mIoU: 0.2105\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 2/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9918c852ef594353b27b940b0125c5ad"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.6132\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 2/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b540afcbfce45d4a8100c32ede87e42"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 2/25\nTrain Loss: 1.6132\nVal Loss:   1.4248   | Val mIoU: 0.2477\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 3/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a0125c1dda4588a9837d66a1d12ff6"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.3976\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 3/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e312a6c285974c45beb9716236375687"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 3/25\nTrain Loss: 1.3976\nVal Loss:   1.5469   | Val mIoU: 0.2169\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 4/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a92d6329e7e4c80b496c5261e079ec2"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.3105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 4/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f60aa68a24fe49a481bf6841318a2a12"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 4/25\nTrain Loss: 1.3105\nVal Loss:   1.5165   | Val mIoU: 0.2560\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 5/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73e8ae0d56a241089d2c3eafb20b9f9e"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2893\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 5/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c161b27092aa4746bb0b9c3e78e8cb25"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 5/25\nTrain Loss: 1.2893\nVal Loss:   1.4232   | Val mIoU: 0.2815\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 6/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89aa0edc0abe4e32a83fca005076b38a"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.2047\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 6/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"309dacdb9b914c90afeb2c03d4516b8c"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 6/25\nTrain Loss: 1.2047\nVal Loss:   1.3578   | Val mIoU: 0.3040\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 7/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c7bed430f074ce28c04c0db00cfc263"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.1338\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 7/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9efbce253aee489e8ed9b8dae9421bee"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 7/25\nTrain Loss: 1.1338\nVal Loss:   1.5023   | Val mIoU: 0.2898\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 8/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e6f3eaeaf41417a8a4864463ed8d889"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.1201\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 8/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40673c44662b45e6940fdb9aebfababf"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 8/25\nTrain Loss: 1.1201\nVal Loss:   1.4365   | Val mIoU: 0.2931\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 9/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d437a638f3234a80968688bb7d27a2cb"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.0622\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 9/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3b5bddc728849f591807ec1f214edf9"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 9/25\nTrain Loss: 1.0622\nVal Loss:   1.5097   | Val mIoU: 0.3111\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 10/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a886fedd508d4fa1833f362202506a50"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 1.0240\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 10/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"388548aaf3ef4d1d9dd5064c62bdc450"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 10/25\nTrain Loss: 1.0240\nVal Loss:   1.5330   | Val mIoU: 0.3239\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 11/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"531a250365b740dab9dc5ce292696cb5"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9674\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 11/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47d2e0d681cd4ac4b1762caddf048926"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 11/25\nTrain Loss: 0.9674\nVal Loss:   1.5419   | Val mIoU: 0.3232\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 12/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee421eac4f814875a76d3ebf707e6a7e"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9609\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 12/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97b185f4edc44478bfe75b760b4349b5"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 12/25\nTrain Loss: 0.9609\nVal Loss:   1.5795   | Val mIoU: 0.3268\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 13/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f36be2b4be646b6b3982756636916e5"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9119\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 13/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c051f9ae86e4848a4865181cc40a379"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 13/25\nTrain Loss: 0.9119\nVal Loss:   1.4723   | Val mIoU: 0.3413\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 14/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a43a19cc8e74aeb84b6cb9e1c6e61d6"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9182\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 14/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"479a6e89bfe14a529f92104c54099b2e"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 14/25\nTrain Loss: 0.9182\nVal Loss:   1.5468   | Val mIoU: 0.3470\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 15/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee17341569d14019a8fa6d2d0a4170f4"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.9156\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 15/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"acfb714ad87841e7bc879c96342c2ecf"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 15/25\nTrain Loss: 0.9156\nVal Loss:   1.6993   | Val mIoU: 0.3205\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 16/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e836dcbe264d7aa91681f5f64209e9"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.8769\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 16/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b066b9c713974e1886377cb97790aaed"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 16/25\nTrain Loss: 0.8769\nVal Loss:   1.7084   | Val mIoU: 0.3443\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 17/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a551aa038be5438ba52d9d0d9edd4489"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.8364\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 17/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8e87c43f9a64ecbb8ee5da1be953527"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 17/25\nTrain Loss: 0.8364\nVal Loss:   1.6203   | Val mIoU: 0.3349\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 18/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8dbda8fc7304e02b6a9406c2a356631"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.8190\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 18/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10627208727c47e79d79681cf2afda05"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 18/25\nTrain Loss: 0.8190\nVal Loss:   1.5870   | Val mIoU: 0.3496\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 19/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0b5b7d4c7bc488ca80b11272c814ade"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.7935\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 19/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44b3ef0d7eb14f0290fc0f7009d4798f"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 19/25\nTrain Loss: 0.7935\nVal Loss:   1.6081   | Val mIoU: 0.3477\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 20/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b0bc7f97240404b904196a59c6f8e83"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.8080\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 20/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44fd52a451174439b751f13ac4c6c554"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 20/25\nTrain Loss: 0.8080\nVal Loss:   1.5948   | Val mIoU: 0.3589\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 21/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74148519176b4183b5adc11035210e89"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.7872\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 21/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"932edead7fb14c9b8df612c929ccf51a"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 21/25\nTrain Loss: 0.7872\nVal Loss:   1.5790   | Val mIoU: 0.3597\n==============================\n\nModel disimpan (best so far).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 22/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b1903b733248c8bcb7368fe83fc52d"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.7853\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 22/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35ad4d6d423e4691bb7310cbff4b6858"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 22/25\nTrain Loss: 0.7853\nVal Loss:   1.5878   | Val mIoU: 0.3570\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 23/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73f283e2ca2d403297fe91b2377af3b5"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.7968\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 23/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9f00799941e4556b2c31559e6baaec0"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 23/25\nTrain Loss: 0.7968\nVal Loss:   1.6138   | Val mIoU: 0.3523\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 24/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b31fcbeca14cc396697db88f4fcec4"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.7730\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 24/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2825e753f12f48cd81c07fe661972fd4"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 24/25\nTrain Loss: 0.7730\nVal Loss:   1.6232   | Val mIoU: 0.3592\n==============================\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train 25/25:   0%|          | 0/29 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad9ad3f8ccb2495a9c8baaed084e5514"}},"metadata":{}},{"name":"stdout","text":"ðŸŽ¯ Train Loss: 0.7752\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Val 25/25:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ecc8acbe0514e6e8c9db1bc59685684"}},"metadata":{}},{"name":"stdout","text":"\n============================== Epoch: 25/25\nTrain Loss: 0.7752\nVal Loss:   1.6242   | Val mIoU: 0.3528\n==============================\n\nTraining Selesai!\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import json\n\nWORKDIR=\"/kaggle/working\"\noutput_path = WORKDIR+\"/history_csdnet_finetuned.json\"\n\nwith open(output_path, \"w\") as f:\n    json.dump(history, f, indent=4)\n\nprint(\"File saved to:\", output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:47:51.811603Z","iopub.execute_input":"2025-12-07T02:47:51.812515Z","iopub.status.idle":"2025-12-07T02:47:51.817782Z","shell.execute_reply.started":"2025-12-07T02:47:51.812489Z","shell.execute_reply":"2025-12-07T02:47:51.817129Z"}},"outputs":[{"name":"stdout","text":"File saved to: /kaggle/working/history_csdnet_finetuned.json\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"import torch\nfrom tqdm.auto import tqdm\nfrom torchmetrics import JaccardIndex  \n\ndef test_model(model, test_loader, device):\n    metric = JaccardIndex(\n        task=\"multiclass\", \n        num_classes=NUM_CLASSES, \n        ignore_index=255,\n        average=\"none\" \n    ).to(device)\n\n    # model.to(device)\n    \n    model.eval()\n    test_loss = 0.0\n    print(\"Mulai Testing (menggunakan JaccardIndex)...\")\n    \n    with torch.no_grad():\n        for images, masks in tqdm(test_loader, desc=\"Testing\"):\n            \n            images, masks = images.to(device), masks.to(device)\n\n            preds = model(images)\n            \n            loss = total_loss_fn(preds, masks)\n            test_loss += loss.item()\n\n            pred_mask = torch.argmax(preds, dim=1)\n            metric.update(pred_mask, masks)\n    \n    iou_per_class = metric.compute()\n    \n    mIoU = iou_per_class.mean().item()\n    \n    print(\"\\n=== HASIL TESTING ===\")\n    print(f\"Mean IoU (mIoU): {mIoU:.4f}\")\n    print(\"-\" * 30)\n    \n    class_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n                   \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n    \n    for i, iou in enumerate(iou_per_class):\n        name = class_names[i] if i < len(class_names) else f\"Class {i}\"\n        print(f\"{name:25s}: {iou.item():.4f}\")\n        \n    metric.reset()\n    return mIoU, iou_per_class","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:47:53.836678Z","iopub.execute_input":"2025-12-07T02:47:53.837487Z","iopub.status.idle":"2025-12-07T02:47:53.844162Z","shell.execute_reply.started":"2025-12-07T02:47:53.837460Z","shell.execute_reply":"2025-12-07T02:47:53.843576Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn.functional as F\n\nmodel = CSDNet(num_classes=NUM_CLASSES)\n\nTRAINED_MODEL = \"/kaggle/working/best_model_csdnet_finetuned.pth\"\n\nif os.path.exists(TRAINED_MODEL):\n    print(f\"Loading weights from: {TRAINED_MODEL}\")\n    checkpoint = torch.load(TRAINED_MODEL, map_location=\"cpu\")\n    \n    if 'state_dict' in checkpoint:\n        state_dict = checkpoint['state_dict']\n    elif 'model' in checkpoint:\n        state_dict = checkpoint['model']\n    else:\n        state_dict = checkpoint\n\n    try:\n        msg = model.load_state_dict(state_dict, strict=True)\n        print(\"\\nâœ… SUKSES: Semua bobot berhasil di-load (termasuk classifier head).\")\n        print(msg) \n    except RuntimeError as e:\n        print(f\"âŒ Error Loading: {e}\")\n        msg = model.load_state_dict(state_dict, strict=False)\n        print(\"Warning: Loaded with strict=False (Check missing keys carefully!)\")\n        print(msg)\n\nelse:\n    print(f\"Error: File {TRAINED_MODEL} tidak ditemukan.\")\n\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T03:01:05.590855Z","iopub.execute_input":"2025-12-07T03:01:05.591801Z","iopub.status.idle":"2025-12-07T03:01:06.489833Z","shell.execute_reply.started":"2025-12-07T03:01:05.591775Z","shell.execute_reply":"2025-12-07T03:01:06.489043Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n","output_type":"stream"},{"name":"stdout","text":"Loading weights from: /kaggle/working/best_model_csdnet_finetuned.pth\n\nâœ… SUKSES: Semua bobot berhasil di-load (termasuk classifier head).\n<All keys matched successfully>\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"CSDNet(\n  (encoder): EfficientNetFeatures(\n    (conv_stem): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNormAct2d(\n      48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (blocks): Sequential(\n      (0): Sequential(\n        (0): DepthwiseSeparableConv(\n          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (bn1): BatchNormAct2d(\n            48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pw): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): DepthwiseSeparableConv(\n          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n          (bn1): BatchNormAct2d(\n            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): DepthwiseSeparableConv(\n          (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n          (bn1): BatchNormAct2d(\n            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (1): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n          (bn2): BatchNormAct2d(\n            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n          (bn2): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n          (bn2): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n          (bn2): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n          (bn2): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (2): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)\n          (bn2): BatchNormAct2d(\n            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n          (bn2): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n          (bn2): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n          (bn2): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n          (bn2): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (3): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n          (bn2): BatchNormAct2d(\n            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(384, 16, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(16, 384, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (5): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (6): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (4): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(768, 768, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=768, bias=False)\n          (bn2): BatchNormAct2d(\n            768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(768, 32, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(32, 768, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(768, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n          (bn2): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n          (bn2): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n          (bn2): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n          (bn2): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (5): InvertedResidual(\n          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n          (bn2): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (6): InvertedResidual(\n          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1056, bias=False)\n          (bn2): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (5): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1056, 1056, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1056, bias=False)\n          (bn2): BatchNormAct2d(\n            1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1056, 44, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(44, 1056, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1056, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (5): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (6): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (7): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (8): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (6): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(304, 1824, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1824, 1824, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1824, bias=False)\n          (bn2): BatchNormAct2d(\n            1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1824, 76, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(76, 1824, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1824, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n          (bn2): BatchNormAct2d(\n            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(512, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(3072, 3072, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3072, bias=False)\n          (bn2): BatchNormAct2d(\n            3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (aa): Identity()\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(3072, 128, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(128, 3072, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(3072, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n    )\n  )\n  (mod1_detection): TargetedEnhancementModule(\n    (aspp_f1): ASPP(\n      (aspp_blocks): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Sequential(\n          (0): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (2): Sequential(\n          (0): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (3): Sequential(\n          (0): Conv2d(24, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n      )\n      (global_pool): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n        (1): Conv2d(24, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): ReLU(inplace=True)\n      )\n      (project): Sequential(\n        (0): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n    (phi): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (mod2_transformer): DeepContextualAttention(\n    (dwsc_in): DWSC(\n      (depthwise): Conv2d(176, 176, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=176, bias=False)\n      (pointwise): Conv2d(176, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (transformer): TransformerEncoder(\n      (layers): ModuleList(\n        (0-1): 2 x TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n          )\n          (linear1): Linear(in_features=128, out_features=256, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (linear2): Linear(in_features=256, out_features=128, bias=True)\n          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n          (dropout1): Dropout(p=0.1, inplace=False)\n          (dropout2): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (aspp): ASPP(\n      (aspp_blocks): ModuleList(\n        (0): Sequential(\n          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (1): Sequential(\n          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (2): Sequential(\n          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (3): Sequential(\n          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n      )\n      (global_pool): Sequential(\n        (0): AdaptiveAvgPool2d(output_size=(1, 1))\n        (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (3): ReLU(inplace=True)\n      )\n      (project): Sequential(\n        (0): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Dropout(p=0.5, inplace=False)\n      )\n    )\n  )\n  (mod3_cnn): MultiScaleFusion(\n    (psi2): Conv2d(40, 128, kernel_size=(1, 1), stride=(1, 1))\n    (psi3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n    (fusion_conv): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (classifier): Sequential(\n    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.1, inplace=False)\n    (4): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (detector_dummy_layer): Conv2d(3, 256, kernel_size=(32, 32), stride=(32, 32))\n)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# class_names = [\"Background\", \"Building Flooded\", \"Building Non-Flooded\",  \n#                    \"Road Flooded\", \"Road Non-Flooded\", \"Water\", \"Tree\", \"Vehicle\", \"Pool\", \"Grass\"]\n\ntest_mIoU, test_iou_per_class = test_model(model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T03:01:11.628127Z","iopub.execute_input":"2025-12-07T03:01:11.628763Z","iopub.status.idle":"2025-12-07T03:01:13.342535Z","shell.execute_reply.started":"2025-12-07T03:01:11.628738Z","shell.execute_reply":"2025-12-07T03:01:13.341799Z"}},"outputs":[{"name":"stdout","text":"Mulai Testing (menggunakan JaccardIndex)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00ada217d6e14f329b261fdef740d7d7"}},"metadata":{}},{"name":"stdout","text":"\n=== HASIL TESTING ===\nMean IoU (mIoU): 0.3898\n------------------------------\nBackground               : 0.2266\nBuilding Flooded         : 0.8048\nBuilding Non-Flooded     : 0.6953\nRoad Flooded             : 0.3176\nRoad Non-Flooded         : 0.2647\nWater                    : 0.2393\nTree                     : 0.5716\nVehicle                  : 0.0989\nPool                     : 0.0000\nGrass                    : 0.6796\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# import numpy as np\n# import torch\n# import os\n# from matplotlib.patches import Patch\n\n# CLASS_NAMES = [\n#     \"Background\",               \n#     \"Water\",                    \n#     \"Building No Damage\",       \n#     \"Building Minor Damage\",    \n#     \"Building Major Damage\",    \n#     \"Building Total Destruction\",\n#     \"Road-Clear\",               \n#     \"Road-Blocked\",             \n#     \"Vehicle\",                  \n#     \"Tree\",                     \n#     \"Pool\"                      \n# ]\n\n# LABEL_COLORS = np.array([\n#     [0, 0, 0],         # Background \n#     [30, 230, 255],    # Water \n#     [184, 115, 117],   # Building No Damage\n#     [216, 255, 0],     # Building Minor Damage\n#     [252, 199, 0],     # Building Major Damage\n#     [255, 0, 0],       # Building Total Destruction\n#     [140, 140, 140],   # Road-Clear\n#     [151, 0, 255],     # Road-Blocked\n#     [255, 0, 246],     # Vehicle \n#     [0, 255, 0],       # Tree\n#     [244, 255, 0]      # Pool\n# ])\n# def decode_segmap(mask):\n#     r = np.zeros_like(mask).astype(np.uint8)\n#     g = np.zeros_like(mask).astype(np.uint8)\n#     b = np.zeros_like(mask).astype(np.uint8)\n    \n#     for l in range(0, len(LABEL_COLORS)):\n#         idx = mask == l\n#         r[idx] = LABEL_COLORS[l, 0]\n#         g[idx] = LABEL_COLORS[l, 1]\n#         b[idx] = LABEL_COLORS[l, 2]\n        \n#     rgb = np.stack([r, g, b], axis=2)\n#     return rgb\n\n# def find_indices_by_filename(dataset, target_ids):\n#     found_indices = []\n#     for target in target_ids:\n#         found = False\n#         for idx, path in enumerate(dataset.image_path):\n#             if str(target) in os.path.basename(path):\n#                 found_indices.append(idx)\n#                 found = True\n#                 break\n#         if not found:\n#             return \n#     return found_indices\n\n# def visualize_specific_images(model, dataset, target_ids, device, processor):\n#     model.eval()\n    \n#     indices = find_indices_by_filename(dataset, target_ids)\n\n#     num_samples = len(indices)\n#     fig, axes = plt.subplots(num_samples, 3, figsize=(18, 6 * num_samples))\n    \n#     if num_samples == 1:\n#         axes = axes.reshape(1, -1)\n\n#     for row_idx, idx in enumerate(indices):\n#         image, mask = dataset[idx] \n        \n#         filename = os.path.basename(dataset.image_path[idx])\n        \n#         inputs = processor(\n#             images=[image], \n#             return_tensors=\"pt\",\n#             do_resize=False, \n#             do_rescale=False\n#         )\n#         inputs = {k: v.to(device) for k, v in inputs.items()}\n        \n#         with torch.no_grad():\n#             outputs = model(**inputs)\n        \n#         target_sizes = [(mask.shape[0], mask.shape[1])]\n#         pred_map = processor.post_process_semantic_segmentation(\n#             outputs, target_sizes=target_sizes\n#         )[0] \n        \n#         img_np = image.permute(1, 2, 0).numpy()\n        \n#         mask_rgb = decode_segmap(mask.numpy())\n#         pred_rgb = decode_segmap(pred_map.cpu().numpy())\n        \n#         axes[row_idx, 0].imshow(img_np)\n#         axes[row_idx, 0].set_title(f\"ID: {filename}\\nOriginal Image\")\n#         axes[row_idx, 0].axis(\"off\")\n        \n#         axes[row_idx, 1].imshow(mask_rgb)\n#         axes[row_idx, 1].set_title(\"Ground Truth\")\n#         axes[row_idx, 1].axis(\"off\")\n        \n#         axes[row_idx, 2].imshow(pred_rgb)\n#         axes[row_idx, 2].set_title(\"Mask2Former Prediction\")\n#         axes[row_idx, 2].axis(\"off\")\n\n#     handles = [Patch(color=LABEL_COLORS[i]/255.0, label=CLASS_NAMES[i]) for i in range(len(CLASS_NAMES))]\n#     fig.legend(handles=handles, loc='lower center', ncol=6, bbox_to_anchor=(0.5, 0.0), fontsize=12)\n\n#     plt.savefig('visualisasi_prediksi_rescuenet.png', bbox_inches='tight', dpi=300)\n    \n#     plt.tight_layout()\n#     plt.subplots_adjust(bottom=0.08) \n#     plt.show()\n\n# target_ids = [\"10794\", \"10801\", \"10807\"]\n\n# visualize_specific_images(model, test_dataset, target_ids, device, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:11.109946Z","iopub.status.idle":"2025-12-07T02:30:11.110149Z","shell.execute_reply.started":"2025-12-07T02:30:11.110054Z","shell.execute_reply":"2025-12-07T02:30:11.110063Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model.eval()\n# import matplotlib.pyplot as plt\n\n# test_imgs, test_masks = next(iter(test_loader))\n\n# with torch.no_grad():\n#     inputs = [{\"image\": test_imgs[0].to(cfg.MODEL.DEVICE), \"height\": 512, \"width\": 512}]\n    \n#     outputs = model(inputs)\n    \n#     pred_mask = outputs[0][\"sem_seg\"].argmax(dim=0).cpu().numpy()\n\n# plt.figure(figsize=(10, 5))\n# plt.subplot(1, 2, 1); plt.title(\"Prediction\"); plt.imshow(pred_mask)\n# plt.subplot(1, 2, 2); plt.title(\"Ground Truth\"); plt.imshow(test_masks[0])\n# plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T02:30:11.111858Z","iopub.status.idle":"2025-12-07T02:30:11.112174Z","shell.execute_reply.started":"2025-12-07T02:30:11.112017Z","shell.execute_reply":"2025-12-07T02:30:11.112031Z"}},"outputs":[],"execution_count":null}]}